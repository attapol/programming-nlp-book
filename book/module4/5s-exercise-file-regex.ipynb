{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QkoLriuAHFQ"
   },
   "source": [
    "# โจทย์: การประมวลผลข้อมูลจากไฟล์\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFJNT7NgXQbR"
   },
   "source": [
    "##  ข้อ 1 - สุนทรพจน์ของโอบามา\n",
    "\n",
    "ไฟล์ [obama.txt](https://drive.google.com/file/d/1iA1s-yNIhdCQvo4BS8d7CVBICHZs4okt/view) ประกอบด้วยสุนทรพจน์ของบารัค โอบามาในปี 2013 ความพิเศษของไฟล์นี้คือมีการระบุประเภทของคำ (Part of speech tags) กล่าวคือ \n",
    "แต่ละคำในไฟล์จะถูกกำกับด้วยประเภทของคำ เช่น คำนาม (noun), คำกริยา (verb), คำสรรพนาม (pronoun) หรือเครื่องหมายวรรคตอนแบบต่าง ๆ เช่น ประโยค\n",
    "\n",
    "```\n",
    "Thank you. God bless you, and may He forever bless these United States of America.\n",
    "```\n",
    "\n",
    "จะปรากฏในไฟล์เป็น\n",
    "\n",
    "```\n",
    "Thank_VV you_PP ._SENT God_NP bless_VVP you_PP ,_, and_CC may_MD He_PP forever_RB bless_VV these_DT United_NP States_NPS of_IN America_NP ._SENT\n",
    "```\n",
    "\n",
    "โดยที่แต่ละคำและเครื่องหมายวรรคตอนจะถูกตามด้วยเครื่องหมายขีดล่าง (_) และตัวหนังสือพิมพ์ใหญ่ทั้งหมด ซึ่งตัวพิมพ์ใหญ่ที่ตามมาเป็นตัวย่อที่ระบุถึงประเภทของคำ (เรียกว่า tag) เช่น VV หมายถึง Verb, PP หมายถึง Pronouns, NN หมายถึง noun, SENT หมายถึงเครื่องหมายจุด (full stop)\n",
    "\n",
    "1. เขียนโปรแกรมเพื่อคำนวณของความถี่ประเภทของคำแต่ละประเภท\n",
    "2. เขียนโปรแกรมหาคำที่ปรากฏบ่อยที่สุด 100 อันดับแรก\n",
    "\n",
    "คำใบ้:\n",
    "\n",
    "* ทดสอบกับข้อความตัวอย่างข้างต้นก่อน\n",
    "* แยกสตริงออกมาเป็นคำ ๆ ในรูปแบบของลิสต์\n",
    "* วนลูปไปบนลิสต์และแยกคำกับประเภทของคำออกจากกัน\n",
    "* ใช้ `Counter` ในการเก็บความถี่ \n",
    "* เมื่อดำเนินการข้างต้นเสร็จแล้ว ลองเปิดไฟล์และอ่านทีละบรรทัด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ดาวน์โหลดไฟล์\n",
    "!wget 'https://drive.google.com/uc?id=1iA1s-yNIhdCQvo4BS8d7CVBICHZs4okt' -O obama.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# สร้าง Counter เพื่อเก็บค่า part-of-speech tags และคำ\n",
    "pos_counter = Counter()\n",
    "word_counter = Counter()\n",
    "\n",
    "# กำหนดรูปแบบ regex เพื่อค้นหาคำและ part-of-speech tags\n",
    "pattern = r'(\\S+?)_([A-Za-z$]+)'\n",
    "\n",
    "# เปิดไฟล์และอ่านไฟล์ทีละบรรทัด\n",
    "with open('obama.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # ค้นหาคำทั้งหมดที่ตรงกับ pattern ในบรรทัดปัจจุบัน\n",
    "        matches = re.findall(pattern, line)\n",
    "        \n",
    "        # อัพเดต Counter ด้วยค่าที่พบ\n",
    "        pos_counter.update(pos for word, pos in matches)\n",
    "        word_counter.update(word for word, pos in matches)\n",
    "\n",
    "# ดึงข้อมูล part-of-speech tags ที่มีความถี่สูงสุดและคำ 100 คำแรก\n",
    "pos_freq = pos_counter.most_common()\n",
    "top_100_word = word_counter.most_common(100)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"\\nความถี่ของ Part-of-Speech Tags:\")\n",
    "for pos, freq in pos_freq:\n",
    "    print(f\"{pos}: {freq}\")\n",
    "\n",
    "print(\"\\nคำ 100 คำแรกที่มีความถี่สูงสุด:\")\n",
    "for word, freq in top_100_word:\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqnLI4XMYvRp"
   },
   "source": [
    "##  ข้อ 2 - ตรวจหาชื่อ\n",
    "ชื่อบุคคลในภาษาอังกฤษ เช่น Peter Meg Lois Brian Stewie จะมีการสะกดแบบพิเศษ คือ ขึ้นต้นด้วยตัวอักษรใหญ่เฉพาะตัวแรกเท่านั้น \n",
    "\n",
    "เขียนฟังก์ชันที่ตรวจสอบว่าคำที่ให้มานั้นมีลักษณะเหมือนชื่อคนภาษาอังกฤษหรือไม่ \n",
    "\n",
    "คำใบ้: ใช้คำสั่ง `re.match` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMNwUfxqZPAC"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def is_name_like(word):\n",
    "    pattern = r'^[A-Z][a-z]*$'\n",
    "    # ใช้ re.match เพื่อตรวจสอบว่าคำตรงกับ pattern หรือไม่ และแปลงผลลัพธ์เป็น boolean\n",
    "    return bool(re.match(pattern, word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NK_A6_ZwaPCR"
   },
   "outputs": [],
   "source": [
    "assert(is_name_like('Brian'))\n",
    "assert(not is_name_like('tangmay'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YT5LzuEWYvux"
   },
   "source": [
    "เขียนฟังก์ชันที่ return ลิสต์ของคำทั้งหมดที่มีแนวโน้มว่าจะเป็นชื่อบุคคลจากประโยคที่กำหนด \n",
    "\n",
    "คำใบ้: ใช้คำสั่ง `re.findall` และอย่าใช้คำสั่ง `str.split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eY02ZvLyZkGP"
   },
   "outputs": [],
   "source": [
    "def get_all_names(sentence):\n",
    "  pattern = r'\\b[A-Z][a-z]*\\b'\n",
    "  # ใช้ re.findall เพื่อค้นหาคำทั้งหมดที่ตรงกับ pattern ในประโยค\n",
    "  names = re.findall(pattern, sentence)\n",
    "  return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RS31LrgragKZ"
   },
   "outputs": [],
   "source": [
    "assert(get_all_names('Joe got married to Bonnie after his PhD in the USA')[0] == 'Joe')\n",
    "assert(get_all_names('Joe got married to Bonnie after his PhD in the USA')[1] == 'Bonnie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4UcDUjSeh5n"
   },
   "source": [
    "เขียนฟังก์ชันที่ทำหน้าที่แทนที่คำที่คาดว่าจะเป็นชื่อบุคคลด้วยสัญลักษณ์ \"XXX\" เพื่อเป็นการเซนเซอร์\n",
    "\n",
    "Hint: ใช้คำสั่ง `re.sub` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOIqB6gbeg9U"
   },
   "outputs": [],
   "source": [
    "def censor_names(sentence):\n",
    "  pattern = r'\\b[A-Z][a-z]*\\b'\n",
    "  # ใช้ re.sub เพื่อแทนที่คำที่ตรงกับ pattern ด้วย \"XXX\"\n",
    "  censored_sentence = re.sub(pattern, 'XXX', sentence)\n",
    "  return censored_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_442u4Nte3bF"
   },
   "outputs": [],
   "source": [
    "assert(censor_names('Joe got married to Bonnie after his PhD in the USA') == 'XXX got married to XXX after his PhD in the USA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecCBUoyu0F3R"
   },
   "source": [
    "##  ข้อ 3 - เครื่องตอบรับอัตโนมัติ\n",
    "\n",
    "หากได้รับสตริงที่เป็นคำถามที่ขึ้นต้นด้วย \"Do\" หรือ \"Does\" ให้ตอบกลับด้วย \"Yes\", ตามด้วยคำตอบที่ใช้คำกริยา \"do\" หรือ \"does\" มาช่วย เช่น\n",
    "\n",
    "`autoanswer('Does he like pop music?') --> 'Yes, he does like pop music.'`\n",
    "\n",
    "`autoanswer('Do you sing well?') --> 'Yes, you do sing well.'`\n",
    "\n",
    "แต่หากไม่ได้เป็นคำถามที่ขึ้นต้นด้วย \"Do\" หรือ \"Does\" ให้เปลี่ยนเป็นประโยคคำถามโดยการเติมเครื่องหมายคำถาม (?) ต่อท้าย เช่น \n",
    "\n",
    "`autoanswer('I do not understand.') --> 'I do not understand?'`\n",
    "\n",
    "Hint: ใช้คำสั่ง `re.match` จากนั้นให้ใช้การอ้างอิงถึงกลุ่ม"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1o934pH0GA6"
   },
   "outputs": [],
   "source": [
    "def autoanswer(question):\n",
    "    # ตรวจสอบว่าประโยคขึ้นต้นด้วย \"Do\" หรือ \"Does\" หรือไม่\n",
    "    match = re.match(r'^(Do|Does) (.*)', question)\n",
    "    if match:\n",
    "        # ถ้าเป็นประโยคคำถามที่ขึ้นต้นด้วย \"Do\" หรือ \"Does\"\n",
    "        verb = match.group(1)\n",
    "        rest_of_sentence = match.group(2)\n",
    "        # แทนที่ \"Do\" หรือ \"Does\" ด้วย \"do\" หรือ \"does\" ตามลำดับ\n",
    "        response_verb = \"do\" if verb == \"Do\" else \"does\"\n",
    "        # สร้างคำตอบในรูปแบบ \"Yes, ... do/does ...\"\n",
    "        return f\"Yes, {rest_of_sentence.split()[0]} {response_verb} {rest_of_sentence[len(rest_of_sentence.split()[0])+1:]}.\"\n",
    "    else:\n",
    "        # ถ้าไม่ใช่ประโยคคำถามที่ขึ้นต้นด้วย \"Do\" หรือ \"Does\"\n",
    "        return f\"{question}?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn_M7evLX18o"
   },
   "source": [
    "## ข้อ 4 - สิ่งที่น่าสนใจเกี่ยวกับคำ\n",
    "\n",
    "ข้อมูลที่ใช้สำหรับการทำแบบฝึกหัดนี้ สามารถดาวน์โหลดได้จากลิงก์ด้านล่าง\n",
    "\n",
    "https://attapol.github.io/programming/data/small_nyt_eng_200001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UgTxUvdtX18p"
   },
   "outputs": [],
   "source": [
    "!wget https://attapol.github.io/programming/data/small_nyt_eng_200001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KboxVkCbizq"
   },
   "source": [
    "หากต้องการใช้ข้อมูลที่มีขนาดใหญ่ขึ้น สามารถใช้ชุดข้อมูล nyt_eng_200001 ได้เช่นกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H89-XcJlE8Fo"
   },
   "outputs": [],
   "source": [
    "!gdown --id 1mHNSEU3NrneejXx-RWFJLEWTi8drInOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "592P1sKicBVX"
   },
   "source": [
    "### 4.1 คำที่มีตัว K \n",
    "ในชุดข้อมูลนี้มีคำที่มีคุณสมบัติต่อไปนี้ปรากฏอยู่ทั้งหมดกี่คำ (นับคำที่ซ้ำกันได้): \n",
    "\n",
    "* คำที่ขึ้นต้นด้วยตัว k \n",
    "\n",
    "* คำที่ตัวที่สองเป็นตัว k \n",
    "\n",
    "* คำที่ลงท้ายด้วยตัว k \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_MsH1aFbfzQ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# อ่านไฟล์ nyt_eng_200001\n",
    "with open('small_nyt_eng_200001', 'r') as file:\n",
    "    s = file.read()\n",
    "\n",
    "# หาคำที่ขึ้นต้นด้วยตัว k\n",
    "pattern_start_k = r'\\bk\\w*'\n",
    "start_k_words = re.findall(pattern_start_k, s)\n",
    "\n",
    "# หาคำที่ตัวที่สองเป็นตัว k\n",
    "pattern_second_k = r'\\b\\w*k\\w*'\n",
    "second_k_words = re.findall(pattern_second_k, s)\n",
    "\n",
    "# หาคำที่ลงท้ายด้วยตัว k\n",
    "pattern_end_k = r'\\b\\w*k\\b'\n",
    "end_k_words = re.findall(pattern_end_k, s)\n",
    "\n",
    "# นับจำนวนคำที่ตรงกับแต่ละ pattern\n",
    "total_words = len(start_k_words) + len(second_k_words) + len(end_k_words)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"จำนวนคำที่ขึ้นต้นด้วยตัว k:\", len(start_k_words))\n",
    "print(\"จำนวนคำที่ตัวที่สองเป็นตัว k:\", len(second_k_words))\n",
    "print(\"จำนวนคำที่ลงท้ายด้วยตัว k:\", len(end_k_words))\n",
    "print(\"จำนวนคำที่มีคุณสมบัติตรงตามที่กำหนดทั้งหมด:\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOKkzIQtdzVx"
   },
   "source": [
    "### 4.2 คำศัพท์ที่ประกอบด้วยตัว k\n",
    "\n",
    "ในชุดข้อมูลนี้มีคำที่มีคุณสมบัติต่อไปนี้ปรากฏอยู่ทั้งหมดกี่คำ โดยไม่นับคำซ้ำด้วยเพื่อให้ได้ขนาดของรายการคำศัพท์ (vocabulary) \n",
    "\n",
    "* คำที่ขึ้นต้นด้วยตัว k \n",
    "\n",
    "* คำที่ตัวที่สองเป็นตัว k \n",
    "\n",
    "* คำที่ลงท้ายด้วยตัว k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkXNl9EwfQsV"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# อ่านไฟล์ nyt_eng_200001\n",
    "with open('small_nyt_eng_200001', 'r') as file:\n",
    "    s = file.read()\n",
    "\n",
    "# หาคำที่ขึ้นต้นด้วยตัว k\n",
    "pattern_start_k = r'\\bk\\w*'\n",
    "start_k_words = set(re.findall(pattern_start_k, s))\n",
    "\n",
    "# หาคำที่ตัวที่สองเป็นตัว k\n",
    "pattern_second_k = r'\\b\\w{k}\\w*'\n",
    "second_k_words = set(re.findall(pattern_second_k, s))\n",
    "\n",
    "# หาคำที่ลงท้ายด้วยตัว k\n",
    "pattern_end_k = r'\\b\\w*k\\b'\n",
    "end_k_words = set(re.findall(pattern_end_k, s))\n",
    "\n",
    "# รวมคำที่ไม่ซ้ำจากทั้งสามชุด\n",
    "all_k_words = start_k_words.union(second_k_words).union(end_k_words)\n",
    "\n",
    "# นับจำนวนคำที่ไม่ซ้ำกัน\n",
    "total_unique_words = len(all_k_words)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"จำนวนคำที่ขึ้นต้นด้วยตัว k (ไม่ซ้ำ):\", len(start_k_words))\n",
    "print(\"จำนวนคำที่ตัวที่สองเป็นตัว k (ไม่ซ้ำ):\", len(second_k_words))\n",
    "print(\"จำนวนคำที่ลงท้ายด้วยตัว k (ไม่ซ้ำ):\", len(end_k_words))\n",
    "print(\"จำนวนคำที่มีคุณสมบัติตรงตามที่กำหนดทั้งหมด (ไม่ซ้ำ):\", total_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ข้อ 5 - ชื่อจากประกาศ\n",
    "\n",
    "เขียนฟังก์ชันชื่อ `find_names` ที่รับพารามิเตอร์เป็นชื่อไฟล์ที่มีข้อความที่มาจากประกาศทางราชการย้อนหลัง 5 ปี ให้ฟังก์ชันนี้คืนค่าเป็นทูเปิลของลิสต์ 2 ลิสต์ ลิสต์แรกเก็บชื่อผู้ชาย ลิสต์ที่สองเก็บชื่อผู้หญิงทั้งหมดที่อยู่ในไฟล์ โดยจะเก็บชื่อจากท้ายประกาศที่มักจะมีชื่อบุคคลที่เซ็นประกาศ เช่น\n",
    "\n",
    "ข้อความในไฟล์\n",
    "```\n",
    "(นายขุนแผน แสนสุภาพ)\n",
    "กรรมการ\n",
    "(นางสาวมณโฑ ตาโตข้างเดียว)\n",
    "หัวหน้าศูนย์สอบภาษาอังกฤษที่ 2 \n",
    "(นางวันทอง กี่ใจก็ได้)\n",
    "ประธานกรรมการโครงการพัฒนาชนบท \n",
    "```\n",
    "ฟังก์ชันต้อง return ค่าเป็นทูเปิลของลิสต์ 2 ลิสต์ ดังนี้\n",
    "```\n",
    "(['ขุนแผน'], ['มณโฑ', 'วันทอง']) \n",
    "```\n",
    "\n",
    "ในไฟล์จะมีข้อความอื่นเพิ่มเติมที่เป็นข้อมูลที่ไม่เกี่ยวข้องมาพร้อมกับประกาศ ดังนั้นเราจึงต้องใช้ regular expression เพื่อค้นหาชื่อที่มีตัวอักษรนำหน้าวงเล็บเปิดตามด้วย นาย นาง หรือ นางสาว "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_names(announcement_file):\n",
    "    # เปิดไฟล์ประกาศเพื่ออ่านข้อมูล\n",
    "    with open(announcement_file, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "      \n",
    "    # กำหนด pattern ของ regex เพื่อจับชื่อในวงเล็บที่มีคำนำหน้าว่า นาย นางสาว หรือ นาง\n",
    "    pattern = r'\\((นาย|นางสาว|นาง)(\\S+)'\n",
    "    \n",
    "    # ใช้ re.findall เพื่อหาข้อความทั้งหมดที่ตรงกับ pattern ใน text\n",
    "    # re.findall จะคืนค่าเป็นลิสต์ของ tuple ที่แต่ละ tuple มีสองส่วนคือคำนำหน้าและชื่อ\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # สร้างลิสต์เปล่าเพื่อเก็บชื่อผู้ชายและผู้หญิง\n",
    "    male_names = []\n",
    "    female_names = []\n",
    "    \n",
    "    # ลูปผ่านผลลัพธ์ที่จับได้จาก regex\n",
    "    for title, name in matches:\n",
    "        # ถ้าคำนำหน้าเป็น \"นาย\" ให้เพิ่มชื่อไปยังลิสต์ male_names\n",
    "        if title == \"นาย\":\n",
    "            male_names.append(name)\n",
    "        # ถ้าคำนำหน้าเป็น \"นางสาว\" หรือ \"นาง\" ให้เพิ่มชื่อไปยังลิสต์ female_names\n",
    "        else:\n",
    "            female_names.append(name)\n",
    "    \n",
    "    # คืนค่าลิสต์ชื่อผู้ชายและผู้หญิง\n",
    "    return male_names, female_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ข้อ 6 - Codeswitching\n",
    "Codeswitch เป็นปรากฏการณ์ทางภาษาศาสตร์หนึ่งที่เกิดขึ้นเมื่อผู้พูดใช้สองภาษาหรือสองสำเนียงผสมกัน (เช่น การพูดไทยคำอังกฤษคำ) \n",
    "\n",
    "เขียนฟังก์ชันที่นับว่าในลิสต์ของคำที่ได้มา มีคำที่สะกดด้วยตัวภาษาอังกฤษกี่คำ และคำที่สะกดด้วยตัวภาษาไทยกี่คำ โดยให้คืนค่าผลลัพธ์เป็นดิกชันนารีที่ key เป็นรหัสภาษา (en สำหรับภาษาอังกฤษ และ th สำหรับภาษาไทย) และ value เป็นจำนวนคำของแต่ละภาษา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import โมดูล regular expression เพื่อใช้ในการหาคำ\n",
    "import re \n",
    "\n",
    "def count_en_th_words(word_list):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    >>> count_en_th_words(['รองเท้า', 'ไม่', 'match', 'กับ', 'coat', 'เลย'])\n",
    "    {'en': 2, 'th': 4}\n",
    "    \"\"\"\n",
    "    # สร้าง dict ที่มีค่าเริ่มต้นของจำนวนคำภาษาอังกฤษและภาษาไทยเป็น 0\n",
    "    result_dict = {'en': 0, 'th': 0}\n",
    "    # วนลูปผ่านคำในรายการคำ\n",
    "    for w in word_list:\n",
    "        # ตรวจสอบว่าคำเป็นภาษาอังกฤษหรือไม่\n",
    "        if re.search('[a-zA-Z]', w):\n",
    "            # ถ้าใช่ เพิ่มจำนวนคำภาษาอังกฤษขึ้น 1\n",
    "            result_dict['en'] += 1\n",
    "        else:\n",
    "            # ถ้าไม่ใช่ เพิ่มจำนวนคำภาษาไทยขึ้น 1\n",
    "            result_dict['th'] += 1\n",
    "\n",
    "    return result_dict"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PC7 Regular Expression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "34368ba4908ea1be08ba769dfb7764ab7f8ead2384ebb5604cb86637573696f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
