

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>บทที่ 9 โมเดลการประมวลผลภาษาธรรมชาติ &#8212; Programming for NLP</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/bookstyle.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'book/module9/1-ml-nlp-model';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Workshop - Word cloud" href="4-workshop-word-cloud.html" />
    <link rel="prev" title="โมเดลการประมวลภาษาธรรมชาติ" href="../9-nlp-models.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    <p class="title logo__title">Programming for NLP</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    บทนำ
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../1-comp_thinking.html">การคิดเชิงคำนวณ (computational thinking)</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module1/1-karel.html">บทที่ 1  การคิดเชิงคำนวณ (Computational Thinking)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module1/2-videos-karel.html">Video: การคิดเชิงคำนวณ และ control flow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module1/3-exercise.html">แบบฝึกหัด: คาเรล</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module1/3s-exercise-solution.html">เฉลยแบบฝึกหัด: คาเรล</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../2-basics.html">ตัวแปร ฟังก์ชัน และสตริง</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module2/1-variable.html">บทที่ 2  ตัวแปร ฟังก์ชัน และสตริง</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module2/2-videos-variable.html">Video: ตัวแปรและฟังก์ชัน</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module2/3-exercise-variable-function.html">แบบฝึกหัด: ตัวแปร และฟังก์ชัน</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module2/3s-exercise-variable-function.html">เฉลยแบบฝึกหัด: ตัวแปร และฟังก์ชัน</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module2/4-videos-string.html">Video: สตริง</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module2/5-exercise-string.html">แบบฝึกหัด: สตริง</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module2/5s-exercise-string.html">เฉลยแบบฝึกหัด: สตริง</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../3-data_structure1.html">โครงสร้างข้อมูล (Data Structure I)</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module3/01-list-dict-tuple-counter-set.html">บทที่ 3  โครงสร้างข้อมูล (Data Structure) I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/02-videos-list.html">Video: List and Data Structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/03-exercise-data-structure.html">แบบฝึกหัด: โครงสร้างข้อมูล I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/03s-exercise-data-structure.html">เฉลยแบบฝึกหัด: โครงสร้างข้อมูล I</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/04-videos-dictionary.html">Video: Dictionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/06-videos-set.html">Video: Set</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/08-comprehension.html">Comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/09-exercise-comprehension.html">โจทย์: Comprehension</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module3/09s-exercise-comprehension.html">เฉลยโจทย์: Comprehension</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4-text_file.html">การประมวลผลข้อมูลจากไฟล์</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module4/1-file-regex.html">บทที่ 4  การประมวลผลข้อมูลจากไฟล์</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module4/2-videos-file.html">Video: file</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module4/4-videos-regex.html">Video: Regular Expression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module4/5-exercise-file-regex.html">โจทย์: การประมวลผลข้อมูลจากไฟล์</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module4/5s-exercise-file-regex.html">เฉลยโจทย์: การประมวลผลข้อมูลจากไฟล์</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../5-data_structure2.html">โครงสร้างข้อมูลแบบซ้อนใน</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module5/1-nested-list.html">บทที่ 5  โครงสร้างข้อมูลแบบซ้อนใน (Nested Data Structure)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module5/2-videos-nested-list.html">Video: Advance list</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module5/4-videos-nested-dictionary.html">Video: Advance dictionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module5/5-exercise-data-type.html">โจทย์: ชนิดของโครงสร้างข้อมูล</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module5/5s-exercise-data-type.html">เฉลยโจทย์: ชนิดของโครงสร้างข้อมูล</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module5/6-exercise-nested.html">โจทย์: โครงสร้างข้อมูลซ้อนใน</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module5/6s-exercise-nested.html">เฉลยโจทย์: โครงสร้างข้อมูลซ้อนใน</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../6-oop.html">การเขียนโปรแกรมเชิงอ็อบเจกต์ (Object-Oriented Programming)</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module6/1-OOP.html">บทที่ 6  การเขียนโปรแกรมเชิงอ็อบเจกต์ (Object-Oriented Programming)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module6/2-videos-OOP.html">Video: Object-Oriented Programming</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module6/3-exercise-OOP.html">โจทย์: การเขียนโปรแกรมเชิงอ็อบเจกต์</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module6/3s-exercise-OOP.html">เฉลยโจทย์: การเขียนโปรแกรมเชิงอ็อบเจกต์</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../7-nlp.html">การประมวลผลภาษาธรรมชาติ (Natural Language Processing)</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module7/1-intro-NLP.html">บทที่ 7  การประมวลผลภาษาธรรมชาติขั้นพื้นฐาน</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module7/2-videos-intro-NLP.html">Video: Natural Language Processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module7/3-workshop-text-processing.html">แบบฝึกหัด: การประมวลผลข้อความขั้นพื้นฐาน</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module7/3s-workshop-text-processing.html">เฉลยแบบฝึกหัดการประมวลผลข้อความ</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../8-pandas.html">การจัดการข้อมูลด้วย pandas</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module8/1-pandas.html">บทที่ 8  การจัดการและวิเคราะห์ข้อมูลแบบตาราง</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module8/2-example-pandas.html">ตัวอย่างการใช้ <code class="docutils literal notranslate"><span class="pre">pandas</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../module8/3-exercise-pandas.html">แบบฝึกหัด</a></li>
<li class="toctree-l2"><a class="reference internal" href="../module8/3s-pandas-exercise-solution.html">เฉลยแบบฝึกหัด</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../9-nlp-models.html">โมเดลการประมวลภาษาธรรมชาติ</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">บทที่ 9  โมเดลการประมวลผลภาษาธรรมชาติ</a></li>
<li class="toctree-l2"><a class="reference internal" href="4-workshop-word-cloud.html">Workshop - Word cloud</a></li>
<li class="toctree-l2"><a class="reference internal" href="5-workshop-lda.html">Workshop - Topic modeling</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../10-llm.html">โมเดลภาษาขนาดใหญ่</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../module10/1-large-language-model.html">บทที่ 10  โมเดลภาษาขนาดใหญ่</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">บรรณานุกรม</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/attapol/programming-nlp-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/attapol/programming-nlp-book/issues/new?title=Issue%20on%20page%20%2Fbook/module9/1-ml-nlp-model.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/book/module9/1-ml-nlp-model.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>บทที่ 9 </br> โมเดลการประมวลผลภาษาธรรมชาติ</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">การติดป้ายกำกับชนิดของคำ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">การจำแนกชนิดของคำ</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">การรู้จำเอนทิตี</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spacy">ไลบรารี spacy สำหรับการติดป้ายชนิดของคำ และการรู้จำเอนทิตี</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sentiment-analysis">การวิเคราะห์อารมณ์ความรู้สึก (Sentiment Analysis)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#huggingface-transformers">แพลตฟอร์ม huggingface และไลบรารี transformers สำหรับการวิเคราะห์อารมณ์ความรู้สึก</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">โมเดลหัวเรื่อง</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gensim-lda">ไลบรารี gensim สำหรับการฝึกโมเดล LDA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">สรุป</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">อ้างอิง</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="br">
<h1>บทที่ 9 </br> โมเดลการประมวลผลภาษาธรรมชาติ<a class="headerlink" href="#br" title="Permalink to this heading">#</a></h1>
<p>การประมวลผลภาษาธรรมชาติ คือ เทคนิควิธีที่ใช้ในการประมวลผลและทำความเข้าใจข้อมูลตัวอักษร โดยอาศัยโมเดลทางภาษา โมเดลหรือโมเดลที่เราพูดถึงนี้หมายถึง การเขียนโปรแกรมที่จำลองการทำความเข้าใจภาษาในด้านต่าง ๆ ซึ่งการจำลองอาจจะไม่ได้สอดคล้องกับวิธีที่มนุษย์ทำความเข้าใจภาษา แต่ว่าโมเดลจำลองพฤติกรรมการประมวลผลภาษาได้ดีพอ ที่จะนำไปใช้ในการทำงานที่เกี่ยวข้องกับภาษาธรรมชาติได้
งานที่สามารถใช้โมเดลการประมวลผลภาษาธรรมชาติได้อย่างมีประสิทธิภาพ และพบเห็นได้บ่อย ๆ ได้แก่ การติดป้ายกำกับชนิดของคำ (part-of-speech tagging) การตรวจจับเอนติตี้ (named-entity recognition) การวิเคราะห์อารมณ์ความรู้สึก (sentiment analysis) โมเดลหัวเรื่อง (topic model) การแปลด้วยเครื่อง (machine translation) ซึ่งทั้งหมดนี้คือต่างใช้การเรียนรู้ของเครื่อง (machine learning) ในการสร้างโมเดลสำหรับงานเหล่านี้ขึ้นมา กล่าวคือเราเขียนโปรแกรมที่เรียนรู้การทำงานเหล่านี้โดยการหาแพทเทิร์นจากชุดข้อมูลที่เหมาะสม เราไม่ได้ตั้งโปรแกรมให้ทำงานตามกฎของภาษาศาสตร์โดยตรง</p>
<p>ในปัจจุบันเราสามารถดาวน์โหลดโมเดลและนำมาประยุกต์ใช้ได้ทันทีโดยที่ต้องไม่ทำการสร้างโมเดลใหม่ตั้งแต่ต้น แต่ว่าอาจจะมีโมเดลสำหรับบางงานและบางภาษาเท่านั้น และโมเดลของแต่ละภาษามีประสิทธิภาพ และความแม่นยำแตกต่างกันไป ในบทนี้เราจะเรียนรู้วิธีการใช้ไลบรารีเพื่อดาวน์โหลดและประยุกต์ใช้โมเดลในการวิเคราะห์ข้อมูลภาษาโดยอัตโนมัติ</p>
<section id="id1">
<h2>การติดป้ายกำกับชนิดของคำ<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<p>ป้ายกำกับชนิดของคำ (part-of-speech tag) ในเชิงภาษาศาสตร์ถูกสร้างขึ้นมาเป็นส่วนหนึ่งของกฎไวยากรณ์ของภาษาที่กำหนดว่าคำชนิดใดสามารถมีความสัมพันธ์กับคำชนิดใด ในลักษณะไหนได้บ้าง  นอกจากนั้นแล้วยังมีบทบาทสำคัญในการทำความเข้าใจความหมายและโครงสร้างของประโยค
เนื่องจากช่วยให้เรารู้ว่าแต่ละคำในประโยคทำหน้าที่อะไร  เช่น คำนาม (noun) มักจะทำหน้าที่เป็นประธานของประโยค หรือเป็นส่วนเติมเต็มของกริยา หรือ คุณศัพท์ (adjective) มักจะทำหน้าที่เป็นตัวขยายความหมายของคำนาม เป็นต้น</p>
<aside class="margin sidebar">
<p class="sidebar-title">คำศัพท์</p>
<p>ชนิดของคำ (part-of-speech) ชนิดของคำแบ่งตามลักษณะไวยากรณ์</p>
</aside>
<p>ในการประมวลผลภาษาธรรมชาติ ชนิดของคำมักจะช่วยในการสกัดข้อมูล (information extraction) จากข้อมูลที่เป็นข้อความ เช่น ถ้าหากเราต้องการสกัดเอาชื่อของบุคคลจากข้อความ เราอาจจะเลือกเอาเฉพาะคำที่เป็นคำนามมาพิจารณาเท่านั้น หรือถ้าหากเราต้องการสกัดคำหลักที่บ่งบอกถึงความหมายใจความสำคัญของคลังเอกสาร เราอาจจะเลือกเฉพาะไบแกรมที่มีคำนามและคำกริยามาพิจารณาเท่านั้น</p>
<aside class="margin sidebar">
<p class="sidebar-title">คำศัพท์</p>
<p>การสกัดข้อมูล (information extraction) การสกัดข้อมูลเฉพาะที่ต้องการจากข้อมูลที่ไม่มีโครงสร้าง เช่น ข้อความ ข่าว</p>
</aside>
<section id="id2">
<h3>การจำแนกชนิดของคำ<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h3>
<p>ทฤษฎีการจำแนกชนิดของคำมีอยู่หลากหลายทฤษฎี แต่ละทฤษฎีต่างก็จำแนกชนิดของคำในจำนวนแตกต่างกัน ทั้งนี้นักเรียนไทยมักจะคุ้นเคยกับการจำแนกชนิดของคำตามหลักภาษาไทยของพระยาอุปกิตศิลปสารซึ่งจำแนกชนิดของคำเป็น 7 ชนิด ได้แก่ คำนาม คำสรรพนาม คำวิเศษณ์ คำกริยา คำบุพบท คำสันธาน และคำอุทาน อย่างไรก็ตามในการประมวลผลภาษาธรรมชาติ เรามักใช้ทฤษฎีของ ชุดป้ายกำกับชนิดของคำสากล (Universal Part-of-speech Tagset) <span id="id3">[<a class="reference internal" href="#id29" title="Slav Petrov, Dipanjan Das, and Ryan McDonald. A universal part-of-speech tagset. In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet Uğur Doğan, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12), 2089–2096. Istanbul, Turkey, May 2012. European Language Resources Association (ELRA). URL: http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf.">Petrov <em>et al.</em>, 2012</a>]</span>      ทฤษฎีนี้กำหนดชนิดของคำออกเป็น 17 ชนิด ซึ่งสามารถจัดออกเป็น 3 กลุ่มใหญ่ ได้แก่</p>
<aside class="margin sidebar">
<p class="sidebar-title">คำศัพท์</p>
<p>ชุดป้ายกำกับชนิดของคำสากล (Universal Part-of-speech Tagset) ชุดป้ายกำกับที่ถูกพัฒนาขึ้นเพื่อรองรับการกำกับชนิดคำต่างภาษาให้เป็นไปในรูปแบบเดียวกัน</p>
</aside>
<ol class="arabic simple">
<li><p>กลุ่มคำเปิด (open class word) คือ กลุ่มคำที่สามารถเพิ่มคำใหม่เข้าไปได้เรื่อย ๆ คำเปิดมักมีความหมายที่ชัดเจนและสามารถปรากฏได้โดยไม่ต้องพึ่งพาคำอื่น เช่น การกระทำ คน สัตว์ สิ่งของ สถานที่ กลุ่มคำเปิดประกอบด้วยคำ 6 ชนิด ได้แก่</p>
<ul class="simple">
<li><p>คำวิเศษณ์ (adverb)</p></li>
<li><p>คำคุณศัพท์ (adjective)</p></li>
<li><p>คำอุทาน (interjection)</p></li>
<li><p>คำนาม (noun)</p></li>
<li><p>คำกริยา (verb)</p></li>
<li><p>วิสามานยนาม หรือคำนามชื่อเฉพาะ (proper noun)</p></li>
</ul>
</li>
<li><p>กลุ่มคำปิด (closed class word) คือ กลุ่มคำที่มีจำนวนจำกัดและไม่ค่อยมีการเพิ่มคำใหม่ หน้าที่หลักของคำปิดคือการเชื่อมโยงหรือจัดระเบียบความสัมพันธ์ระหว่างคำในประโยค คำปิดมักมีความหมายที่น้อยลงหรือเป็นนามธรรม และปรากฏได้ก็ต่อเมื่อมีความสัมพันธ์กับคำอื่นเพื่อสร้างประโยคที่ถูกหลักไวยากรณ์ กลุ่มคำปิดประกอบด้วยคำ 8 ชนิด ได้แก่</p>
<ul class="simple">
<li><p>คำบุพบท (adposition)</p></li>
<li><p>คำช่วยกริยา (auxiliary)</p></li>
<li><p>คำนำหน้านาม (determiner)</p></li>
<li><p>ตัวเลข (numeral)</p></li>
<li><p>คำอนุภาค (particle)</p></li>
<li><p>คำสรรพนาม (pronoun)</p></li>
<li><p>คำสันธานเชื่อมความ (coordinating conjunction)</p></li>
<li><p>คำสันธานซ้อนความ (subordinating conjunction)</p></li>
</ul>
</li>
<li><p>กลุ่มคำชนิดอื่น ๆ ประกอบด้วยคำ 3 ชนิด ได้แก่</p>
<ul class="simple">
<li><p>เครื่องหมายวรรคตอน (punctuation)</p></li>
<li><p>สัญลักษณ์ (symbol)</p></li>
<li><p>คำอื่น ๆ ที่ไม่เข้าพวกกับคำชนิดที่กล่าวมาแล้ว</p></li>
</ul>
</li>
</ol>
<p>ชุดป้ายกำกับชนิดของคำสากลเป็นระบบการจำแนกชนิดของคำที่มีมาตรฐานเดียวกันทุกภาษา เพื่อให้การทำงานของโมเดลภาษาต่าง ๆ สามารถทำงานร่วมกันได้โดยสะดวกต่อการใช้โมเดลที่มีการใช้การถ่ายโอนข้ามภาษา (cross-lingual transfer) การใช้ชุดป้ายกำกับชนิดของคำสากล จึงเป็นเครื่องมือที่สำคัญและได้รับความนิยมในการพัฒนาระบบประมวลผลภาษาธรรมชาติที่มีประสิทธิภาพ</p>
</section>
</section>
<section id="id4">
<h2>การรู้จำเอนทิตี<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h2>
<p>เอนทิตี (entity) ในเชิงทฤษฎี คือ สิ่งที่มีตัวตนจริงและอิสระไม่เกี่ยวพันกับสิ่งอื่น ๆ ซึ่งเรามักจะหมายถึงบุคคล องค์กร บริษัท หรือสถานที่ ดังนั้นเอนทิตีที่มีชื่อเรียก (named entity) แปลตรงตัวแล้วจะหมายถึงบุคคล องค์กร บริษัท หรือสถานที่ที่มีการตั้งชื่อเรียก
แต่ในบริบทของการประมวลผลภาษาธรรมชาติ การรู้จำเอนทิตี (Named-Entity Recognition หรือ NER) หมายความกว้างกว่านั้น การรู้จำเอนทิตี หมายถึงการตรวจจับชื่อของบุคคล ชื่อขององค์กร ชื่อของสถานที่ ชื่อของเหตุการณ์ วันเดือนปี หรือชื่อของสิ่งของอื่น ๆ ที่มีความสำคัญออกมาจากข้อความ และในทางปฏิบัติแล้วการรู้จำเอนทิตีไม่ได้จำกัดเพียงแต่เอนทิตีอย่างเดียว แต่หมายความรวมถึงการตรวจจับส่วนอื่นของข้อความที่มีความสำคัญ​และอาจจะไม่ได้มีตัวตนอิสระตามความหมายของเอนทิตี เช่น</p>
<aside class="margin sidebar">
<p class="sidebar-title">คำศัพท์</p>
<p>เอนทิตี (entity) (ทั่วไป) สิ่งหรือแนวคิดที่มีตัวตนอยู่</p>
</aside>
<ul class="simple">
<li><p>เวลาและวันที่ เช่น “เมื่อวาน” หรือ “สัปดาห์หน้า”</p></li>
<li><p>จำนวนเงิน เช่น “500 บาท” หรือ “หนึ่งพันเหรียญสหรัฐ”</p></li>
<li><p>จำนวนและขนาด เช่น “3 กิโลเมตร” หรือ “5 ลิตร”</p></li>
<li><p>คำนำหน้าชื่อ และคำศัพท์ทั่วไปที่เป็นคำบ่งบอกสถานที่ เช่น “เด็กชาย” “นางสาว” หรือ “โรงเรียน” ซึ่งไม่ได้บ่งบอกถึงชื่อเฉพาะของบุคคลหรือสถานที่</p></li>
</ul>
<p>การรู้จำเอนทิตีมีประโยชน์อย่างมากในการประยุกต์ใช้การประมวลผลภาษาธรรมชาติ โดยสามารถยกตัวอย่างได้ดังนี้</p>
<ul class="simple">
<li><p>ในการวิเคราะห์ความเห็นของลูกค้าเกี่ยวกับผลิตภัณฑ์ในโซเชียลมีเดีย บริษัทสามารถใช้การรู้จำเอนทิตีเพื่อระบุชื่อผลิตภัณฑ์ ชื่อบริษัท หรือบุคคลที่เกี่ยวข้อง จากนั้นสามารถวิเคราะห์ความเห็นในเชิงบวกหรือลบที่มีต่อเอนทิตีเหล่านี้ได้อย่างมีประสิทธิภาพ ซึ่งช่วยให้บริษัทสามารถเข้าใจความคิดเห็นของลูกค้าเกี่ยวกับผลิตภัณฑ์หรือบริการได้อย่างละเอียด และสามารถปรับปรุงผลิตภัณฑ์และการบริการตามความคิดเห็นที่ได้รับได้อย่างตรงจุด</p></li>
<li><p>ในระบบตอบคำถามอัตโนมัติ เช่น ระบบบริการหลังการขายออนไลน์  การรู้จำเอนทิตีสามารถระบุข้อมูลสำคัญจากคำถามของผู้ใช้ เช่น ชื่อผลิตภัณฑ์ หรือปัญหาที่เกิดขึ้น ทำให้ระบบสามารถให้คำตอบที่แม่นยำและรวดเร็วแก่ผู้ใช้ ลดเวลาที่ต้องใช้ในการค้นหาข้อมูลและเพิ่มประสิทธิภาพในการให้บริการลูกค้า</p></li>
<li><p>ในด้านการสกัดข้อมูลทางการแพทย์ การรู้จำเอนทิตีมีบทบาทสำคัญในการวิเคราะห์เวชระเบียนหรือเอกสารทางการแพทย์ โดยสามารถระบุชื่อโรค ชื่อยา ชื่อแพทย์ หรือวันนัดหมายได้อย่างชัดเจน ซึ่งช่วยในการจัดการข้อมูลทางการแพทย์อย่างเป็นระบบ สามารถสกัดข้อมูลสำคัญเพื่อใช้ในการวินิจฉัยโรค หรือการวิจัยทางการแพทย์ได้อย่างรวดเร็วและแม่นยำ</p></li>
<li><p>ในการวิเคราะห์ข่าวสารจากแหล่งต่าง ๆ การรู้จำเอนทิตีสามารถระบุชื่อบุคคลสำคัญ เหตุการณ์สำคัญ สถานที่ หรือชื่อองค์กรที่ปรากฏในข่าว ทำให้สำนักข่าวหรือองค์กรที่เกี่ยวข้องสามารถติดตามและวิเคราะห์ข้อมูลข่าวสารได้อย่างมีประสิทธิภาพ สามารถสรุปแนวโน้มข่าวสาร หรือทำการวิจัยเชิงลึกเกี่ยวกับประเด็นที่สำคัญได้</p></li>
</ul>
<p>การรู้จำเอนทิตีมักจะใช้เทคนิคการประมวลผลภาษาธรรมชาติเช่นเดียวกับการจำแนกชนิดของคำ โดยใช้โมเดลการเรียนรู้ของเครื่องที่เรียนรู้จากชุดข้อมูลที่มีเอนทิตีที่ถูกติดป้ายกำกับไว้ และใช้เอนทิตีที่ติดป้ายกำกับเหล่านั้นในการสร้างโมเดลที่สามารถรู้จำเอนทิตีใหม่ได้</p>
</section>
<section id="spacy">
<h2>ไลบรารี spacy สำหรับการติดป้ายชนิดของคำ และการรู้จำเอนทิตี<a class="headerlink" href="#spacy" title="Permalink to this heading">#</a></h2>
<p>การติดป้ายชนิดของคำ (part-of-speech tagging) และการรู้จำเอนทิตีอัตโนมัติจำเป็นต้องใช้โมเดลแบบการเรียนรู้ของเครื่องในการแยก เพราะฉะนั้นไลบรารีที่ใช้จะต้องมีโมเดลเหล่านี้เตรียมไว้ให้พร้อมใช้ ไลบรารี spacy เป็นไลบรารีที่รองรับการประมวลผลภาษาธรรมชาติหลากหลายภาษา รวมถึงมีโมเดลการประมวลผลภาษาธรรมชาติหลากหลายขนาดให้เลือกใช้ตามความเหมาะสม และตามข้อจำกัดในการนำโมเดลไปใช้จริง  <span id="id5">[<a class="reference internal" href="#id28" title="Matthew Honnibal and Ines Montani. spaCy 2: natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing. To appear, 2017.">Honnibal and Montani, 2017</a>]</span> ปัจจุบัน (2024) spacy รองรับการติดป้ายชนิดของคำสำหรับภาษาหลายภาษา เช่น ภาษาอังกฤษ ภาษาสเปน ภาษาฝรั่งเศส ภาษาจีน ภาษาญี่ปุ่น ภาษาเกาหลี แต่ว่า spacy ยังไม่มีโมเดลในการประมวลผลภาษาไทย</p>
<p>ขั้นแรกต้องหาชื่อชุดโมเดลที่เราต้องการใช้ รายชื่อชุดโมเดลอยู่บนเว็บไซต์ของ spacy ซึ่งมีเอกสารประกอบการใช้งานที่เป็นปัจจุบันอยู่ โมเดลเหล่านี้ประกอบไปด้วยโมเดลย่อยหลาย ๆ โมเดลด้วยกัน เราสามารถตรวจสอบดูบนเว็บไซต์ได้ว่าโมเดลแต่ละชุดประกอบด้วยโมเดลอะไรบ้าง  ตัวอย่างเช่น สำหรับภาษาจีน มีชุดโมเดลที่มีโมเดลการแยกชนิดของคำได้อยู่สามโมเดลได้แก่ <code class="docutils literal notranslate"><span class="pre">zh_core_web_sm</span></code> (ขนาดเล็ก) <code class="docutils literal notranslate"><span class="pre">zh_core_web_md</span></code> (ขนาดกลาง) และ  <code class="docutils literal notranslate"><span class="pre">zh_core_web_lg</span></code> (ขนาดใหญ่) ทั้งสามชุดในเวอร์ชันปี 2024 ประกอบไปด้วย 5 โมเดลย่อย ได้แก่ โมเดลการตัดคำ โมเดลการตัดประโยค โมเดลการวิเคราะห์โครงสร้างประโยค โมเดลการติดป้ายชนิดของคำ โมเดลการรู้จำเอนทิตี</p>
<p>หากเรายังไม่ได้ติดตั้งไลบรารี spacy เราสามารถติดตั้งโดยใช้คำสั่ง <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">spacy</span></code> หลังจากนั้นเราสามารถดาวน์โหลดและติดตั้งโมเดลที่ต้องการได้โดยใช้คำสั่ง <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">-m</span> <span class="pre">spacy</span> <span class="pre">download</span></code> ตามด้วยชื่อโมเดลที่ต้องการดาวน์โหลดและติดตั้ง เช่น</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>-m<span class="w"> </span>spacy<span class="w"> </span>download<span class="w"> </span>zh_core_web_md
</pre></div>
</div>
<p>วิธีการใช้ spacy จะต่างจากการใช้ pythainlp ตรงที่ว่าเราจะต้องสร้างอ็อบเจกต์ที่ทำหน้าที่เป็นตัวประมวลผลที่โหลดโมเดลที่ต้องการมาให้พร้อม เพื่อที่จะได้ไม่ต้องโหลดโมเดลซ้ำ ๆ เพราะการโหลดโมเดลขนาดใหญ่ซ้ำ ๆ จะทำให้โปรแกรมทำงานช้า ไม่เหมาะกับการประมวลผลข้อมูลขนาดใหญ่ที่เรามักจะต้องวนซ้ำการประมวลผลบนข้อมูลทีละชิ้น ตัวอย่างการใช้งาน spacy ในการจำแนกชนิดของคำแสดงในโค้ดต่อไปนี้</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;zh_core_web_md&#39;</span>
<span class="n">nlp_processor</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
<span class="n">text</span>  <span class="o">=</span> <span class="s1">&#39;张伟和李娜在漂亮的上海吃饭&#39;</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp_processor</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">pos_</span><span class="p">)</span>
</pre></div>
</div>
<p>ผลลัพธ์ที่ได้จะแสดงชนิดของคำที่แยกออกมาจากข้อความ ตามที่กำหนดไว้ในชุดป้ายกำกับชนิดของคำสากลดังนี้</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">张伟</span> <span class="n">PROPN</span>
<span class="n">和</span> <span class="n">CCONJ</span>
<span class="n">李娜</span> <span class="n">PROPN</span>
<span class="n">在</span> <span class="n">ADP</span>
<span class="n">漂亮</span> <span class="n">VERB</span>
<span class="n">的</span> <span class="n">PART</span>
<span class="n">上海</span> <span class="n">PROPN</span>
<span class="n">吃饭</span> <span class="n">VERB</span>
</pre></div>
</div>
<p>ในตัวอย่างนี้เราโหลดโมเดล <code class="docutils literal notranslate"><span class="pre">zh_core_web_md</span></code> ซึ่งเป็นโมเดลขนาดกลางสำหรับภาษาจีน โดยการเรียกคำสั่ง <code class="docutils literal notranslate"><span class="pre">spacy.load</span></code> เพื่อสร้างตัวประมวลผลข้อความและเก็บไว้ในตัวแปรชื่อ <code class="docutils literal notranslate"><span class="pre">nlp_processor</span></code> ซึ่งสามารถใช้ได้คล้ายกับว่าเป็นฟังก์ชัน เราจึงสามารถเรียก <code class="docutils literal notranslate"><span class="pre">nlp_processor(text)</span></code> ได้เลยโดยไม่ต้องใช้ชื่อเมท็อดอื่น ผลที่ได้คือเป็น <code class="docutils literal notranslate"><span class="pre">Doc</span></code> อ็อบเจกต์ที่เราสามารถวนลูปเพื่อดึง <code class="docutils literal notranslate"><span class="pre">Token</span></code> อ็อบเจกต์ออกมาและดึงชนิดของคำออกมาได้โดยใช้ <code class="docutils literal notranslate"><span class="pre">token.pos_</span></code> ในการเข้าถึงชนิดของคำ</p>
<p>ข้อสังเกตที่สำคัญอีกประการหนึ่งของการใช้ spacy คือ ไลบรารีนี้ประมวลข้อความเป็นแบบการทำงานแบบสายท่อ (pipeline) กล่าวคือสตริงที่รับเข้ามาจะถูกประมวลหลาย ๆ ขั้นในครั้งเดียว เช่น การประมวลภาษาจีนจะเริ่มด้วยการตัดคำ ต่อด้วยการแยกชนิดของคำ การวิเคราะห์โครงสร้างประโยค และจบด้วยการรู้จำเอนทิตี จากนั้นผู้ใช้สามารถเข้าถึงผลการวิเคราะห์ทั้งหมดนี้ผ่าน <code class="docutils literal notranslate"><span class="pre">Doc</span></code> อ็อบเจกต์ที่ได้รับกลับมาจากการเรียก <code class="docutils literal notranslate"><span class="pre">nlp_processor(text)</span></code> โดยไม่ต้องเรียกแต่ละขั้นตอนเอง  เพราะฉะนั้นเราสามารถเข้าถึงรายชื่อเอนทิตีได้เลย โดยไม่ต้องประมวลผลข้อความอีกครั้ง</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
   <span class="nb">print</span><span class="p">(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
<p>ผลลัพท์ที่ได้จะแสดงสตริงที่อ้างถึงเอนทิตี และชนิดของเอนทิตี ดังนี้</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">张伟</span> <span class="n">PERSON</span>
<span class="n">李娜</span> <span class="n">PERSON</span>
<span class="n">上海</span> <span class="n">GPE</span>
</pre></div>
</div>
<p>จากข้อความตัวอย่างที่ป้อนเข้าไป ตัวประมวลผลรู้จำชื่อเอนทิตีที่เป็นบุคคลทั้งหมดสองชื่อ ได้แก่  张伟 (จางเหว่ย) และ 李娜 (หลีน่า) และเอนทิตีแบบภูมิรัฐศาสตร์ (GPE ซึ่งย่อมาจาก geopolitical entity) หนึ่งชื่อ 上海 (เมืองเซี่ยงไฮ้)</p>
</section>
<section id="sentiment-analysis">
<h2>การวิเคราะห์อารมณ์ความรู้สึก (Sentiment Analysis)<a class="headerlink" href="#sentiment-analysis" title="Permalink to this heading">#</a></h2>
<p>การวิเคราะห์อารมณ์ความรู้สึก คือ กระบวนการในการตรวจจับและจำแนกอารมณ์หรือความรู้สึกที่แสดงออกมาในข้อความ โดยใช้เทคนิคทางด้านการประมวลผลภาษาธรรมชาติ และการเรียนรู้ของเครื่อง การวิเคราะห์อารมณ์ความรู้สึกมักถูกใช้เพื่อประเมินความคิดเห็นของผู้ที่ใช้งานระบบ หรือผู้บริโภคที่มีต่อผลิตภัณฑ์ บริการ รวมถึงการประเมินความคิดเห็นของบุคคลทั่วไปที่มีต่อเหตุการณ์ต่าง ๆ โดยสามารถจำแนกออกเป็นอารมณ์เชิงบวก เชิงลบ หรือเป็นกลาง การวิเคราะห์อารมณ์ความรู้สึกนับว่าเป็นการประยุกต์ใช้การประมวลผลภาษาธรรมชาติในโลกของวิทยาการข้อมูลที่เห็นเด่นชัด และเป็นที่นิยมที่สุดชนิดหนึ่งในปัจจุบัน ตัวอย่างของการวิเคราะห์อารมณ์ความรู้สึกมีอยู่หลากหลายแบบ เช่น</p>
<aside class="margin sidebar">
<p class="sidebar-title">คำศัพท์</p>
<p>การวิเคราะห์อารมณ์ความรู้สึก (sentiment analysis) การวิเคราะห์และจัดกลุ่มอารมณ์ความรู้สึกที่ปรากฏในข้อความหรือข้อมูล</p>
</aside>
<ul class="simple">
<li><p>การวิเคราะห์ความคิดเห็นของลูกค้าในโซเชียลมีเดีย: สมมติว่าเรามีข้อความจากทวิตเตอร์เกี่ยวกับผลิตภัณฑ์ใหม่ของบริษัท เราสามารถแยกแยะความคิดเห็นเชิงบวก ลบ หรือกลาง และนับจำนวนความคิดเห็นแต่ละประเภทได้ และแยกวิเคราะห์ได้ บริษัทสามารถใช้ข้อมูลนี้เพื่อเข้าใจความคิดเห็นของลูกค้าต่อผลิตภัณฑ์ใหม่ และนำไปปรับปรุงผลิตภัณฑ์หรือกลยุทธ์การตลาดได้</p></li>
<li><p>การประเมินความพึงพอใจของลูกค้าในบทวิจารณ์ออนไลน์:
การวิเคราะห์อารมณ์ความรู้สึกสามารถแยกแยะได้ว่าอาจจะมีความรู้สึกเชิงบวกต่อผลิตภัณฑ์ แต่มีความรู้สึกเชิงลบต่อการบริการ ร้านอาหารสามารถใช้ข้อมูลนี้เพื่อปรับปรุงการบริการและรักษาคุณภาพอาหารให้ดีอยู่เสมอ</p></li>
<li><p>การวิเคราะห์อารมณ์ความรู้สึกที่อยู่เอกสารทางการเงิน ทุก ๆ ปีบริษัทที่มีการซื้อขายหุ้นอยู่ในตลาดหลักทรัพย์ จะต้องเผยแพร่เอกสารรายงานผลประกอบการที่จะต้องพูดถึงบริษัทในหลากหลายด้าน เช่น เรื่องผลกำไรขาดทุน ความเสี่ยงในการประกอบธุรกิจ การควบรวมกับบริษัทอื่น การพัฒนากำลังคน หรือการเปลี่ยนแปลงในโครงสร้างบริษัท นักวิเคราะห์สามารถวิเคราะห์อารมณ์ความรู้สึกในเอกสารรายงานผลประกอบการ เพื่อให้ได้ดัชนีในการชี้วัดว่าผู้เขียนมีความคิดเห็นในด้านบวก ลบ หรือกลางในด้านใดบ้างในปีที่ผ่านมา ซึ่งมีการศึกษามาว่าผลการวิเคราะห์ในลักษณะดังกล่าวมีความสัมพันธ์ร่วมกันกับผลตอบแทนเกินปกติ (abnormal return) ดังนั้นการวิเคราะห์อารมณ์ความรู้สึกจึงสามารถช่วยให้นักลงทุนหรือผู้บริหารบริษัทมีดัชนีชี้วัดเพิ่มอีกตัวหนึ่งที่ช่วยในการตัดสินใจลงทุนในสินทรัพย์ต่าง ๆ ได้อย่างมีประสิทธิภาพมากขึ้น</p></li>
<li><p>การติดตามความคิดเห็นเรื่องการเมืองบนสื่อออนไลน์: การศึกษาเรื่องวิเคราะห์อารมณ์ความรู้สึกที่อยู่บนสื่อออนไลน์ เช่น เว็บไซต์ reddit สามารถช่วยให้นักวิเคราะห์เข้าใจความคิดเห็นของประชาชนต่อเรื่องการเมือง เนื่องจากเหตุการณ์ทางการเมืองต่าง ๆ ส่งผลต่ออารมณ์ความรู้สึกที่ปรากฏอยู่ในสื่อเหล่านี้ <span id="id6">[<a class="reference internal" href="#id30" title="Jakapun Tachaiya, Joobin Gharibshah, Kevin E Esterling, and Michalis Faloutsos. Raffman: measuring and analyzing sentiment in online political forum discussions with an application to the trump impeachment. In Proceedings of the International AAAI Conference on Web and Social Media, volume 15, 703–713. 2021.">Tachaiya <em>et al.</em>, 2021</a>]</span> การวิเคราะห์อารมณ์ความรู้สึกบนฟอรัมออนไลน์มีประโยชน์อย่างมากในการทำความเข้าใจและตอบสนองต่อความคิดเห็นของประชาชนได้อย่างมีประสิทธิภาพ โดยช่วยให้เราสามารถติดตามการเปลี่ยนแปลงของอารมณ์ความรู้สึกในช่วงเวลาต่าง ๆ เมื่อเกิดเหตุการณ์สำคัญ เช่น การถอดถอนประธานาธิบดี ซึ่งจะเป็นประโยชน์ในการระบุแนวโน้มทางการเมืองและสังคม นอกจากนี้ ยังสามารถช่วยในการวิเคราะห์แนวโน้มการแบ่งขั้วทางการเมืองหรือความรู้สึกที่มีต่อประเด็นสำคัญในสังคมอีกด้วย</p></li>
</ul>
<p>การวิเคราะห์อารมณ์ความรู้สึกในเชิงปฏิบัติ คือ การแยกประเภทของข้อความว่าเป็นข้อความที่แสดงความเห็นในด้านบวก ด้านลบ หรือเป็นกลาง เราสามารถคิดว่าตัววิเคราะห์อารมณ์ความรู้สึก (sentiment analyzer) เป็นฟังก์ชันที่รับสตริงข้อความ และคืนค่าเป็นป้ายกำกับ (label) ที่บ่งบอกว่าข้อความนั้นเป็นเชิงบวก ลบ หรือเป็นกลาง โดยใช้เทคนิคการเรียนรู้ของเครื่อง ซึ่งสามารถทำได้ด้วยการใช้ชุดข้อมูลที่มีป้ายกำกับความรู้สึกเช่นข้อความที่มีป้ายกำกับว่าเป็นเชิงบวก ลบ หรือเป็นกลาง ในการสร้างโมเดลการเรียนรู้ของเครื่อง โดยใช้ข้อมูลเหล่านี้ในการเรียนรู้ว่าคุณลักษณะของข้อความที่เป็นเชิงบวก ลบ หรือกลาง คืออะไร และใช้คุณลักษณะเหล่านั้นในการจำแนกประเภทของข้อความใหม่ที่ยังไม่เคยเห็นมาก่อน หนึ่งในชุดข้อมูลที่ได้รับความนิยมมากในการนำมาสร้างตัววิเคราะห์อารมณ์ความรู้สึก คือ Sentiment Treebank  ซึ่งนำมาแสดงให้ดูเป็นตัวอย่างดังนี้ โดยเลือกเฉพาะตัวอย่างที่มีคำว่า <em>excellent</em> ซึ่งแปลว่ายอดเยี่ยมอยู่อย่างน้อย 1 จุด <span id="id7">[<a class="reference internal" href="#id31" title="Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 conference on empirical methods in natural language processing, 1631–1642. 2013.">Socher <em>et al.</em>, 2013</a>]</span></p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p>ข้อความ</p></th>
<th class="head"><p>ป้ายกำกับ</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>(a)</p></td>
<td><p>Leguizamo and Jones are both excellent and the rest of the cast is uniformly superb.</p></td>
<td><p>บวก</p></td>
</tr>
<tr class="row-odd"><td><p>(b)</p></td>
<td><p>Still, this flick is fun, and host to some truly excellent sequences.</p></td>
<td><p>บวก</p></td>
</tr>
<tr class="row-even"><td><p>(c)</p></td>
<td><p>A potentially good comic premise and excellent cast are terribly wasted.</p></td>
<td><p>ลบ</p></td>
</tr>
<tr class="row-odd"><td><p>(d)</p></td>
<td><p>There’s an excellent 90-minute film here; unfortunately, it runs for 170</p></td>
<td><p>ลบ</p></td>
</tr>
<tr class="row-even"><td><p>(e)</p></td>
<td><p>So brisk is Wang’s pacing that none of the excellent cast are given air to breathe.</p></td>
<td><p>เป็นกลาง</p></td>
</tr>
</tbody>
</table>
<p>ข้อสังเกตที่สำคัญอย่างหนึ่งจากตัวอย่างข้างต้น คือ ถึงแม้ว่าทุกข้อความจะมีคำว่า <em>excellent</em> อยู่  แต่ก็ไม่ได้หมายความว่าอารมณ์ความรู้สึกที่ส่งผ่านข้อความนั้นจะเป็นบวกเสมอไป ยังมีปัจจัยทางบริบทที่มีผลต่อการตีความโดยรวม เช่น บริบททางโครงสร้างประโยคในตัวอย่าง (c) นำเอาคำว่า <em>excellent</em> มาใช้เป็นส่วนขยายของนามแต่ว่าไม่ได้นำมาใช้เป็นส่วนหนึ่งของกริยาหลัก ซึ่งมีผลต่อความหมายโดยรวมของประโยคมากกว่า ทำให้เห็นว่าเราต้องคำนึงปัจจัยทางภาษาศาสตร์อื่น ๆ อีกมาก นอกเหนือจากความหมายของคำ จึงจะสามารถวิเคราะห์อารมณ์ความรู้สึกได้ถูกต้อง</p>
</section>
<section id="huggingface-transformers">
<h2>แพลตฟอร์ม huggingface และไลบรารี transformers สำหรับการวิเคราะห์อารมณ์ความรู้สึก<a class="headerlink" href="#huggingface-transformers" title="Permalink to this heading">#</a></h2>
<p>Huggingface เป็นแพลตฟอร์ม (ระบบที่ทุกคนเข้าใช้ร่วมกัน แทนที่จะมีคนกลุ่มเดียวที่เข้าใช้ได้) ที่มุ่งเน้นการพัฒนาและแบ่งปันโมเดลการประมวลผลภาษาธรรมชาติที่มีความสามารถหลากหลาย กล่าวคือนักพัฒนาสามารถนำโมเดลที่ตนสร้างขึ้นมาฝากไว้บนแพลตฟอร์มนี้ เพื่อให้ผู้ใช้คนอื่นเข้ามาโหลดเพื่อนำไปใช้ได้อย่างสะดวก ซึ่งหน้าที่ของแพลตฟอร์มคืออำนวยความสะดวกให้ทั้งสองฝ่ายโดยไม่ต้องพัฒนาโมเดลทั้งหมดเอง</p>
<aside class="margin sidebar">
<p class="sidebar-title">คำศัพท์</p>
<p>แพลตฟอร์ม (platform) กรอบการทำงานที่ให้บริการระบบเพื่อให้ผู้ใช้งานสามารถสื่อสารและทำงานร่วมกันได้อย่างมีประสิทธิภาพ</p>
</aside>
<p>แพลตฟอร์ม huggingface อยู่บนเว็บไซต์ <a class="reference external" href="https://huggingface.co">https://huggingface.co</a>  และมาพร้อมกับไลบรารีที่เรียกว่า transformers ซึ่งเป็นไลบรารีไพทอนที่ช่วยโหลดโมเดลมาจากแพลตฟอร์ม เพื่อนำไปพัฒนาเป็นระบบอื่น ๆ ในภาษาไพทอนได้อย่างสะดวก huggingface รวมโมเดลที่ถูกพัฒนามาแล้วหลากหลายรุ่นที่สามารถนำไปใช้ในงานต่าง ๆ ได้ทันที ถ้าหากเราค้นหาโมเดล sentiment analysis บนแพลตฟอร์ม ก็จะพบว่ามีโมเดลให้เลือกกว่า 100 โมเดล เราจำเป็นต้องดูว่าโมเดลใดรองรับภาษาที่เราต้องการวิเคราะห์ รวมถึงตรวจสอบอีกว่าความแม่นยำที่คาดหวังได้คือเท่าไร ผู้ที่นำโมเดลมาฝากในแพลตฟอร์มนี้มักจะมีเขียนไว้อย่างละเอียดถึงกระบวนการพัฒนาโมเดล เหมาะกับข้อมูลประเภทใด (เช่น ทวีต รีวิว หรือข่าวการเงิน) และความแม่นยำตามที่ได้ประเมินประสิทธิภาพไว้</p>
<p>เริ่มต้นจากการติดตั้งไลบรารีด้วยคำสั่ง <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">transformers</span></code> วิธีการใช้ไลบรารีนี้แบบพื้นฐานที่สุด ทำได้โดยการใช้ฟังก์ชัน <code class="docutils literal notranslate"><span class="pre">pipeline</span></code> ในการโหลดโมเดลและปรับการใช้งาน โดยที่เราจะต้องทราบชื่อโมเดลที่ต้องการใช้
โมเดลที่แนะนำในปัจจุบัน (มิถุนายน 2567) สำหรับการวิเคราะห์อารมณ์ความรู้สึกภาษาไทยคือ <code class="docutils literal notranslate"><span class="pre">poom-sci/WangchanBERTa-finetuned-sentiment</span></code> ซึ่งเรียนรู้การวิเคราะห์มาจากชุดข้อมูลที่เป็นรีวิว รวมกันกับข้อมูลที่เป็นทวีต ทำให้เหมาะกับการวิเคราะห์เบื้องต้น ไม่ได้เฉพาะเจาะจงกับข้อมูลแหล่งใดแหล่งหนึ่ง</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Use a pipeline as a high-level helper</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;text-classification&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;poom-sci/WangchanBERTa-finetuned-sentiment&quot;</span><span class="p">)</span>
<span class="n">pipe</span><span class="p">([</span><span class="s2">&quot;เนื้อครีมลื่นไม่เหนียว&quot;</span><span class="p">,</span> <span class="s2">&quot;กระปุกสีขาว ฝาเกลียว&quot;</span><span class="p">,</span> <span class="s2">&quot;เปิดออกมาแล้วกลิ่นค่อนข้างแรง&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>ผลลัพธ์ที่ได้ออกมาคือ ลิสต์ของดิกชันนารีที่ประกอบด้วยป้ายกำกับ (label) ที่มีค่าความน่าจะเป็นสูงสุดคือป้ายกำกับที่ และค่าความน่าจะเป็น (score) ที่ได้ ดังนี้</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.6775356531143188</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;neu&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9761248230934143</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;neg&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.7795576453208923</span><span class="p">}]</span>
</pre></div>
</div>
<p>ภาษาไทยมีโมเดลอีกตัวหนึ่งซึ่งสร้างขึ้นมาเพื่อข้อมูลที่มาจากเอกสารทางการเงิน เช่น รายงานผลประกอบการ หรือข่าวทางการเงิน โมเดลตัวนี้ชื่อว่า <code class="docutils literal notranslate"><span class="pre">nlp-chula/augment-sentiment-finnlp-th</span></code> บนแพลต์ฟอร์ม huggingface เราสามารถนำมาใช้งานได้ด้วยคำสั่งเดียวกันเพียงแต่เปลี่ยนชื่อโมเดลที่ใช้</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_finance_news</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;text-classification&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="s2">&quot;nlp-chula/augment-sentiment-finnlp-th&quot;</span><span class="p">)</span>
<span class="n">pipe_finance_news</span><span class="p">([</span>
    <span class="s2">&quot;บริษัทยังคงดำเนินนโยบายการขยายเครือข่ายสาขาอย่างต่อเนื่อง&quot;</span><span class="p">,</span> 
     <span class="s2">&quot;ในช่วงครึ่งปีหลัง บริษัทเน้น เรื่องการเร่งรัดติดตามทวงถามหนี้เพิ่มมากขึ้น&quot;</span><span class="p">,</span>
    <span class="s2">&quot;การแพร่ระบาดของไวรัสโควิด-19 ระลอกใหม่เป็นปัจจัย สาคัญที่กดดันต่อการบริโภคภาคเอกชน และการท่องเที่ยว&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ธนาคารมีสินทรัพย์สภาพคล่องประมาณ 47,272 ล้านบาท ลดลงจานวน 2,424 ล้านบาท &quot;</span><span class="p">,</span>
    <span class="s2">&quot;ธุรกิจกองทุนสํารองเลี้ยงชีพของ บลจ. ทิสโก้ยังคงเติบโตกว่าร้อยละ 11.8 เทียบกับ อุตสําหกรรมที่เติบโตลดลงเหลือเพียงร้อยละ 2.1 จากปี 2562&quot;</span><span class="p">])</span>
</pre></div>
</div>
<p>ผลลัพธ์ที่ได้ออกมาคือ</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Neutral&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.6528419256210327</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Neutral&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.937697172164917</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Negative&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9270865321159363</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Negative&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.8279978036880493</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Positive&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.5197721719741821</span><span class="p">}]</span>
</pre></div>
</div>
<p>ข้อควรระวังอย่างหนึ่งของการวิเคราะห์อารมณ์ความรู้สึก คือการเลือกใช้โมเดลให้เหมาะสมกับขอบเขตเนื้อหา (domain) ของข้อมูลที่เราต้องการวิเคราะห์  ถ้าหากชุดข้อมูลที่ใช้พัฒนาโมเดลมีขอบเขตเนื้อหาที่ไม่ตรงกับ ขอบเขตเนื้อหาของข้อมูลที่เราต้องการวิเคราะห์ อาจจะทำให้ความแม่นยำลดลง หรือผลลัพธ์ที่ได้ไม่เป็นที่พอใจ สมมติว่าโมเดลการวิเคราะห์อารมณ์ความรู้สึก (sentiment analysis) ถูกพัฒนามาด้วยข้อมูลรีวิวภาพยนตร์ ซึ่งข้อมูลนี้มีลักษณะเฉพาะ เช่น คำศัพท์และรูปแบบการใช้ภาษาที่เกี่ยวข้องกับการรีวิวภาพยนตร์ หากเรานำโมเดลนี้ไปใช้วิเคราะห์ความคิดเห็นเกี่ยวกับการเงินการลงทุน  โมเดลก็จะมีความแม่นยำลดลง เพราะลักษณะทางภาษาหรือขอบเขตเนื้อหาของข้อมูลรีวิวภาพยนตร์อาจมีความแตกต่างจากข้อมูลความเห็นเกี่ยวกับการเงินการลงทุน  เรียกอีกอย่างว่า ปัญหาการกระจายตัวแบบออกนอกขอบเขต (out-of-distribution) ซึ่งเป็นปัญหาที่สำคัญในการใช้โมเดลการเรียนรู้ของเครื่องในงานปัญญาประดิษฐ์ <span id="id8">[<a class="reference internal" href="#id32" title="Hao Lang, Yinhe Zheng, Yixuan Li, SUN Jian, Fei Huang, and Yongbin Li. A survey on out-of-distribution detection in nlp. Transactions on Machine Learning Research, 2023.">Lang <em>et al.</em>, 2023</a>]</span></p>
<p>ในตัวอย่างการใช้ huggingface ข้างต้น เราได้ลองใช้โมเดลภาษาไทยสองตัวที่ถูกพัฒนาขึ้นมาจากชุดข้อมูลคนละขอบเขตกัน ตัวแรกสร้างขึ้นเพื่อใช้วิเคราะห์รีวิวและทวีต และโมเดลตัวที่สองสร้างขึ้นเพื่อใช้วิเคราะห์ข้อความที่ขอบเขตเนื้อหาคือการเงิน และผลประกอบการของบริษัท
หากเราใช้โมเดลตัวแรกมาวิเคราะห์ข้อความที่พูดถึงเรื่องการเงิน จะได้ผลดังนี้</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;neu&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9173294305801392</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;neu&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9335467219352722</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;neu&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.8750076293945312</span><span class="p">},</span> <span class="c1"># ที่ถูกต้องคือ &#39;neg&#39;</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;neu&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9450038075447083</span><span class="p">},</span> <span class="c1"># ที่ถูกต้องคือ &#39;neg&#39;</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;neu&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.9596440196037292</span><span class="p">}]</span> <span class="c1"># ที่ถูกต้องคือ &#39;pos&#39;</span>
</pre></div>
</div>
<p>หากเราใช้โมเดลตัวที่สองมาวิเคราะห์ที่เป็นรีวิวจะได้ผลดังนี้</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Neutral&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.6709030270576477</span><span class="p">},</span> <span class="c1"># ที่ถูกต้องคือ &#39;Positive&#39;</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Positive&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.5924004316329956</span><span class="p">},</span><span class="c1"># ที่ถูกต้องคือ &#39;Neutral&#39;</span>
 <span class="p">{</span><span class="s1">&#39;label&#39;</span><span class="p">:</span> <span class="s1">&#39;Neutral&#39;</span><span class="p">,</span> <span class="s1">&#39;score&#39;</span><span class="p">:</span> <span class="mf">0.8645471930503845</span><span class="p">}]</span><span class="c1"># ที่ถูกต้องคือ &#39;Negative&#39;</span>
</pre></div>
</div>
<p>เมื่อโมเดลทั้งสองตัวถูกนำไปใช้กับข้อมูลที่ไม่ตรงกับขอบเขตเนื้อหาที่ใช้พัฒนา ความแม่นยำจะลดลง และผลลัพธ์ที่ได้ไม่เป็นที่พอใจ ดังนั้นการเลือกใช้โมเดลที่เหมาะสมกับข้อมูลที่ต้องการวิเคราะห์เป็นสิ่งสำคัญ โดยทั่วไปแล้วโมเดลที่ได้รับความนิยมบนแพลตฟอร์ม huggingface มักจะระบุว่าโมเดลถูกพัฒนาขึ้นมาด้วยชุดข้อมูลอะไร ที่มาของข้อความอยู่ในขอบเขตเนื้อหาอะไร เพื่อผู้ใช้จะได้นำไปประยุกต์ใช้ได้อย่างเหมาะสมกับข้อมูลที่ต้องการวิเคราะห์</p>
</section>
<section id="id9">
<h2>โมเดลหัวเรื่อง<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h2>
<p>โมเดลหัวเรื่อง (topic model) เป็นหนึ่งในโมเดลที่เป็นที่นิยมในการวิเคราะห์หาหัวเรื่องที่อยู่ในชุดเอกสาร จุดประสงค์ของโมเดลหัวเรื่องคือระบุและจัดกลุ่มข้อความที่มีเนื้อหาคล้ายคลึงกัน การทำงานของโมเดลหัวเรื่องนั้นคล้ายกับการวิเคราะห์ความถี่ของคำ (word frequency analysis) เพียงแต่ว่าเราไม่ต้องจัดคำที่ปรากฏบ่อยให้เป็นหมวดหมู่ด้วยตัวเอง โมเดลหัวเรื่องที่ได้รับความนิยมและใช้กันอย่างแพร่หลายคือ Latent Dirichlet Allocation (LDA) ซึ่งเป็นเทคนิคที่ช่วยในการหาหัวเรื่องทั้งหมดที่อยู่ในชุดเอกสารโดยการวิเคราะห์ความน่าจะเป็นของการเกิดร่วมกันของคำในเอกสาร นอกจากนั้นแล้วโมเดล LDA ยังช่วยในการระบุหัวเรื่องหลักในเอกสารแต่ละเอกสารอีกด้วย  ตัวอย่างเช่น หากเรามีชุดเอกสารที่เกี่ยวกับข่าวต่างประเทศ โมเดล LDA อาจช่วยในการระบุหัวเรื่องเช่น “การเมือง”, “เศรษฐกิจ”, และ “กีฬา” ทำให้เราสามารถจัดหมวดหมู่ข้อมูลและวิเคราะห์เชิงลึกได้ง่ายขึ้น นอกจากนี้ โมเดลหัวเรื่องยังสามารถนำไปใช้ในงานต่างๆ เช่น การจัดหมวดหมู่บทความในเว็บไซต์ข่าว การวิเคราะห์เอกสารทางวิชาการเพื่อค้นหาประเด็นวิจัยสำคัญ และการประมวลผลข้อความจากโซเชียลมีเดียเพื่อหาแนวโน้มและความสนใจของผู้ใช้งาน เป็นต้น</p>
<p>โมเดล LDA มีรายละเอียดทางคณิตศาสตร์ที่ซับซ้อน ซึ่งอยู่นอกเหนือขอบเขตของหนังสือเล่มนี้ <span id="id10">[<a class="reference internal" href="#id33" title="David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. Journal of machine Learning research, 3(Jan):993–1022, 2003.">Blei <em>et al.</em>, 2003</a>]</span> อย่างไรก็ตาม เราสามารถเข้าใจหลักการทำงานของ LDA ได้อย่างง่าย ๆ โดยไม่ต้องลงลึกในรายละเอียดสมการของ LDA มากนัก LDA ทำงานโดยการหาคำที่เกิดขึ้นร่วมกันบ่อย ๆ ในเอกสารเดียวกัน สมมติว่าชุดเอกสารที่เราวิเคราะห์มีบทความข่าวทั้งหมด 10 ข่าว ซึ่งอาจจะประกอบไปด้วยข่าวการเมือง ข่าวเศรษฐกิจ และข่าวกีฬา แต่เราไม่ทราบมาก่อนเลยว่าข่าวทั้ง 10 ข่าวนี้จัดกลุ่มเป็นข่าวประเภทใดได้บ้าง แต่เราพอจะคาดเดาได้ว่าน่าจะมีสัก 3 ประเภทด้วยกัน</p>
<p>ข้อสังเกตที่สำคัญที่ทำให้ LDA ทำงานได้อย่างมีประสิทธิภาพคือ เราสามารถจัดหัวเรื่องตามคำหลักได้ และคำหลักที่มาจากหัวเรื่องเดียวกันเหล่านี้มักพบเห็นพร้อมกันในเอกสารเดียวกัน เช่น  ข่าวการเมืองมักจะมีคำเฉพาะเจาะจงที่เกี่ยวข้องกับการเมือง เช่น <em>นายกรัฐมนตรี รัฐบาล รัฐสภา เลือกตั้ง ประกาศ ลงมติ</em> และข่าวการเมืองหนึ่งข่าวมักจะใช้คำเหล่านี้หลาย ๆ คำในข่าวเดียวกัน  ข่าวเศรษฐกิจมักจะมีคำเฉพาะเจาะจงที่เกี่ยวข้องกับเศรษฐกิจ เช่น <em>ธุรกิจ ชะลอตัว ลด การลงทุน ดอกเบี้ย อัตรา เศรษฐกิจ</em> ข่าวการเมืองก็อาจจะใช้คำหลักเหล่านี้บ้าง เพราะว่าข่าวการเมืองก็อาจจะพูดถึงเศรษฐกิจด้วย แต่ว่าไม่ใช่ข่าวการเมืองทุกข่าวจะพูดถึงเศรษฐกิจ เพราะเหตุนี้ผลนี้เอง โมเดล LDA จึงทำงานโดยการตรวจหาคำที่เกิดร่วมกันบ่อย ๆ ในเอกสารเดียวกัน และรวบรวมรายการของคำเหล่านี้รวมกันเป็นหัวเรื่อง เพราะฉะนั้น<em>หัวเรื่อง</em> ที่ได้จาก LDA คือรายการของคำและแต่ละคำมีค่าน้ำหนักบ่งบอกถึงความสำคัญ</p>
<p>หากเราฝึกโมเดล LDA บนเอกสารที่เป็นข่าว 10 ข่าวและกำหนดให้แยกออกมาเป็น 3 หัว หัวเรื่องที่ได้ออกมาเป็นผลลัพท์อาจมีลักษณะดังนี้</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>หัวเรื่อง</p></th>
<th class="head"><p>คำหลัก</p></th>
<th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
<th class="head"><p>4</p></th>
<th class="head"><p>5</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p></p></td>
<td><p>นายกรัฐมนตรี</p></td>
<td><p>รัฐบาล</p></td>
<td><p>รัฐสภา</p></td>
<td><p>ลงมติ</p></td>
<td><p>กรรมการ</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>น้ำหนัก</p></td>
<td><p>0.3</p></td>
<td><p>0.2</p></td>
<td><p>0.1</p></td>
<td><p>0.1</p></td>
<td><p>0.05</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p></p></td>
<td><p>ธุรกิจ</p></td>
<td><p>ชะลอตัว</p></td>
<td><p>ลด</p></td>
<td><p>การลงทุน</p></td>
<td><p>ดอกเบี้ย</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>น้ำหนัก</p></td>
<td><p>0.25</p></td>
<td><p>0.2</p></td>
<td><p>0.2</p></td>
<td><p>0.1</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p></p></td>
<td><p>ฟุตบอล</p></td>
<td><p>บาสเกตบอล</p></td>
<td><p>กรรมการ</p></td>
<td><p>ชนะ</p></td>
<td><p>คะแนน</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p>น้ำหนัก</p></td>
<td><p>0.1</p></td>
<td><p>0.1</p></td>
<td><p>0.1</p></td>
<td><p>0.05</p></td>
<td><p>0.025</p></td>
</tr>
</tbody>
</table>
<p>หัวเรื่องที่ได้จาก LDA มักจะเรียกอีกอย่างหนึ่งว่าคำสำคัญของหัวเรื่อง (topic key) ซึ่งเราจะต้องอ่านและตีความว่าหัวเรื่องแต่ละหัวเรื่องเกี่ยวกับอะไรโดยการเชื่อมโยงหาธีมด้วยตัวเอง ตัวโมเดลเองไม่ได้ประกาศชัดเจนว่าหัวเรื่องที่ 1 2 หรือ 3 เกี่ยวกับอะไร จากตัวอย่างข้างต้นเราตีความว่าหัวเรื่องที่ 1 เกี่ยวกับการเมือง หัวเรื่องที่ 2 เกี่ยวกับเศรษฐกิจ และหัวเรื่องที่ 3 เกี่ยวกับกีฬา</p>
<p>ในกระบวนการวิเคราะห์เดียวกัน LDA ยังจัดกลุ่มเอกสารโดยดูว่ามีเอกสารแต่ละเอกสารมีคำจากหัวเรื่องใดเป็นสัดส่วนเท่าไร ผลลัพธ์คือสัดส่วนของหัวเรื่องแต่ละหัวเรื่องในแต่ละเอกสาร ซึ่งเราจะเรียกว่าตาราง doc-topic เพราะว่าตารางผลลัพธ์จะมีเอกสารอยู่ที่แถวแต่ละแถว และมีหัวเรื่องอยู่ใน เช่น ถ้าหากเรามี 10 เอกสาร</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>เอกสาร</p></th>
<th class="head"><p>หัวเรื่อง 1</p></th>
<th class="head"><p>หัวเรื่อง 2</p></th>
<th class="head"><p>หัวเรื่อง 3</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>0.05</p></td>
<td><p>0.05</p></td>
<td><p>0.9</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>0.1</p></td>
<td><p>0.8</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-even"><td><p>3</p></td>
<td><p>0.8</p></td>
<td><p>0.1</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-odd"><td><p>4</p></td>
<td><p>0.0</p></td>
<td><p>0.05</p></td>
<td><p>0.95</p></td>
</tr>
<tr class="row-even"><td><p>5</p></td>
<td><p>0.5</p></td>
<td><p>0.4</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-odd"><td><p>6</p></td>
<td><p>0.7</p></td>
<td><p>0.3</p></td>
<td><p>0.0</p></td>
</tr>
<tr class="row-even"><td><p>7</p></td>
<td><p>0.1</p></td>
<td><p>0.8</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-odd"><td><p>8</p></td>
<td><p>0.9</p></td>
<td><p>0.05</p></td>
<td><p>0.05</p></td>
</tr>
<tr class="row-even"><td><p>9</p></td>
<td><p>0.95</p></td>
<td><p>0.025</p></td>
<td><p>0.025</p></td>
</tr>
<tr class="row-odd"><td><p>10</p></td>
<td><p>0.1</p></td>
<td><p>0.9</p></td>
<td><p>0.0</p></td>
</tr>
</tbody>
</table>
<p>จากตัวอย่างผลลัพธ์ข้างต้น เอกสารที่ 3 5 7 และ 9 น่าจะเป็นข่าวการเมือง เนื่องจากมีสัดส่วนของหัวเรื่อง 1 มากที่สุด แต่เราสังเกตว่าเอกสารที่ 5 มีสัดส่วนของหัวเรื่อง 1 และ 2 พอ ๆ กัน ซึ่งอาจจะตีความได้ว่าเป็นเอกสารที่พูดถึงทั้งการเมืองและเศรษฐกิจ
ส่วนเอกสารที่ 2 8 และ 10 น่าจะเป็นข่าวเศรษฐกิจ เนื่องจากมีสัดส่วนของหัวเรื่อง 2 มากที่สุด และเอกสารที่ 1 และ 4 น่าจะเป็นข่าวกีฬา เนื่องจากมีสัดส่วนของหัวเรื่อง 3 มากที่สุด</p>
<p>สรุปแล้ว LDA ช่วยในการหาหัวเรื่องที่อยู่ในชุดเอกสาร และจัดกลุ่มเอกสารตามหัวเรื่องที่พบในเอกสารไปในคราวเดียวกัน โดยที่เราไม่ต้องระบุหัวเรื่องล่วงหน้า แต่เราต้องระบุจำนวนหัวเรื่องที่เราคิดว่าเหมาะสมกับชุดเอกสาร
เมื่อฝึกโมเดลเสร็จแล้วเราสามารถตีความหัวเรื่องที่ได้จาก LDA ได้อย่างง่าย ๆ โดยการดูคำหลักที่เกี่ยวข้องกับหัวเรื่องนั้น และดูสัดส่วนของหัวเรื่องในแต่ละเอกสาร</p>
</section>
<section id="gensim-lda">
<h2>ไลบรารี gensim สำหรับการฝึกโมเดล LDA<a class="headerlink" href="#gensim-lda" title="Permalink to this heading">#</a></h2>
<p>ไลบรารี gensim เป็นไลบรารีภาษาไพทอนที่เป็นที่นิยมมากสำหรับการใช้โมเดล LDA ไลบรารีนี้ทำให้การฝึกและใช้งานโมเดล LDA เป็นเรื่องง่ายและมีประสิทธิภาพ ไลบรารีนี้มีฟังก์ชันอำนวยความสะดวกในการเตรียมข้อมูลและการฝึกโมเดล gensim มีเครื่องมือที่ช่วยในการแปลงเอกสารให้เป็นเวกเตอร์และสร้างดิกชันนารีของคำ (dictionary) ซึ่งเป็นขั้นตอนที่สำคัญก่อนที่จะเริ่มฝึกโมเดล LDA นอกจากนี้ gensim ยังมีฟังก์ชันที่ช่วยในการปรับพารามิเตอร์ของโมเดลเพื่อให้ได้ผลลัพท์ที่ออกมามีประโยชน์ที่สุด</p>
<p>ขั้นตอนแรกของการฝึกโมเดลคือการเปลี่ยนข้อมูลให้อยู่ในรูปของลิสต์ของเอกสาร ซึ่งเอกสารหนึ่งเอกสารจะต้องถูกเก็บอยู่ในรูปลิสต์ของคำที่ปราศจากคำหยุด เพราะฉะนั้นเราจะต้องทำการตัดคำ สมมติว่าเราต้องการวิเคราะห์ข้อมูลรีวิวสายการบิน ที่อยู่ในไฟล์ zip ที่มีชื่อไฟล์ว่า Airline_review.csv.zip ซึ่งมีคอลัมน์ <em>Review</em> ที่เก็บข้อมูลรีวิว ขั้นตอนแรกเราจะทำการอ่านข้อมูลจากไฟล์ zip และทำการตัดคำด้วยไลบรารี nltk และเก็บข้อมูลในรูปลิสต์ของคำ โดยเราจะใช้ฟังก์ชัน <code class="docutils literal notranslate"><span class="pre">clean</span></code> ที่เราได้สร้างขึ้นมาเพื่อทำความสะอาดข้อมูล และการตัดคำ</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">zipfile</span> <span class="kn">import</span> <span class="n">ZipFile</span>

<span class="n">zip_file_path</span> <span class="o">=</span> <span class="s1">&#39;Airline_review.csv.zip&#39;</span>

<span class="c1"># อ่าน csv ที่อยู่ในไฟล์ zip โดยที่ไม่ต้อง unzip ออกมาใส่เครื่องเพิ่ม</span>
<span class="k">with</span> <span class="n">ZipFile</span><span class="p">(</span><span class="n">zip_file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="k">with</span> <span class="n">zip_ref</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s1">&#39;Airline_review.csv&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">clean</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># ลบตัวเลขและเครื่องหมายวรรคตอน</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^a-zA-Z\s]&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="c1"># ตัดคำ</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
    <span class="c1"># ต้องระบุคำหยุดใน stop_word_set ก่อน</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_word_set</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">words</span>

<span class="n">reviews</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">clean</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</pre></div>
</div>
<p>โค้ดข้างต้นเรารันฟังก์ชัน <code class="docutils literal notranslate"><span class="pre">clean</span></code> ลงไปบนคอลัมน์ <em>Review</em> ที่อยู่ในดาตาเฟรม และเก็บใส่ตัวแปรชื่อว่า <code class="docutils literal notranslate"><span class="pre">reviews</span></code> ซึ่งมีโครงสร้างเป็นลิสต์ของลิสต์ของสตริง (คำ) ข้อมูลที่อยู่ในรูปนี้เป็นรูปแบบที่พร้อมใช้งานกับไลบรารี gensim และเราสามารถนำไปใช้ในการฝึกโมเดล LDA ได้เลย</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># use gensim to create a dictionary and a corpus</span>
<span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">corpora</span><span class="p">,</span> <span class="n">models</span>

<span class="n">dictionary</span> <span class="o">=</span> <span class="n">corpora</span><span class="o">.</span><span class="n">Dictionary</span><span class="p">(</span><span class="n">reviews</span><span class="p">)</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">dictionary</span><span class="o">.</span><span class="n">doc2bow</span><span class="p">(</span><span class="n">review</span><span class="p">)</span> <span class="k">for</span> <span class="n">review</span> <span class="ow">in</span> <span class="n">reviews</span><span class="p">]</span>
<span class="n">lda_model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">LdaModel</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">num_topics</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">id2word</span><span class="o">=</span><span class="n">dictionary</span><span class="p">,</span> 
                            <span class="n">passes</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>  <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>ในโค้ดข้างต้นเราใช้คลาส <code class="docutils literal notranslate"><span class="pre">gensim.corpora.Dictionary</span></code> ในการสร้างดิกชันนารีของคำ และใช้เมท็อด <code class="docutils literal notranslate"><span class="pre">doc2bow</span></code> ในการแปลงข้อมูลให้อยู่ในรูปของลิสต์ของตัวเลข และเก็บใส่ตัวแปร <code class="docutils literal notranslate"><span class="pre">corpus</span></code> ซึ่งเป็นลิสต์ของลิสต์ของตัวเลข หลังจากนั้นเราใช้คลาส <code class="docutils literal notranslate"><span class="pre">gensim.models.LdaModel</span></code> ในการฝึกโมเดล LDA พารามิเตอร์ที่สำคัญที่สุดคือ จำนวนหัวเรื่อง (<code class="docutils literal notranslate"><span class="pre">num_topics</span></code>) ที่เราต้องการให้โมเดลหา ส่วนพารามิเตอร์อื่น ๆ ที่เกี่ยวข้องกับการฝึกโมเดลสามารถตั้งตามที่เห็นตัวอย่างได้เลย เช่น จำนวนรอบการฝึก (<code class="docutils literal notranslate"><span class="pre">passes</span></code>) เป็น 5 และการกำหนดค่าพารามิเตอร์ <code class="docutils literal notranslate"><span class="pre">alpha</span></code> และ <code class="docutils literal notranslate"><span class="pre">eta</span></code> โดยเราสามารถใช้ค่า <code class="docutils literal notranslate"><span class="pre">auto</span></code>  ส่วน <code class="docutils literal notranslate"><span class="pre">random_state</span></code> สามารถตั้งค่าเป็นอะไรก็ได้ การฝึกโมเดล LDA มีการต้องสุ่มค่าเริ่มต้นการฝึก เพราะฉะนั้นหากเราฝึกโมเดลใหม่อีกครั้งโดยใช้ค่า <code class="docutils literal notranslate"><span class="pre">random_state</span></code> เดียวกันก็จะได้ผลออกมาเหมือนเดิมทุกอย่าง หากไม่ระบุเลยแล้วกดรันอีกครั้งหนึ่งผลจะออกมาแตกต่าง</p>
<p>หลังจากฝึกโมเดลเสร็จเราสามารถดูหัวเรื่องที่ได้จากโมเดลได้ด้วยเมท็อด <code class="docutils literal notranslate"><span class="pre">show_topic</span></code> ซึ่งจะคืนค่าเป็นลิสต์ของทูเปิล (คำ, ค่าน้ำหนัก) เรียงลำดับตั้งแต่มากไปน้อย ตัวอย่างเช่น หากเราเรียก <code class="docutils literal notranslate"><span class="pre">lda_model.show_topic(0)</span></code> จะได้ผลลัพธ์ดังนี้</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[(</span><span class="s1">&#39;flight&#39;</span><span class="p">,</span> <span class="mf">0.035730693</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;good&#39;</span><span class="p">,</span> <span class="mf">0.017981019</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;food&#39;</span><span class="p">,</span> <span class="mf">0.016260142</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;crew&#39;</span><span class="p">,</span> <span class="mf">0.016218152</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;service&#39;</span><span class="p">,</span> <span class="mf">0.01401287</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;cabin&#39;</span><span class="p">,</span> <span class="mf">0.013283503</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="mf">0.011989626</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;seats&#39;</span><span class="p">,</span> <span class="mf">0.00853041</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;friendly&#39;</span><span class="p">,</span> <span class="mf">0.008275962</span><span class="p">),</span>
<span class="p">(</span><span class="s1">&#39;staff&#39;</span><span class="p">,</span> <span class="mf">0.00817701</span><span class="p">)]</span>
</pre></div>
</div>
<p>หากต้องการดูทุกหัวเรื่องโดยดูเฉพาะคำที่มีค่าน้ำหนักสูงสุด 10 คำแรก gensim ไม่ได้มีเมท็อดที่แสดงผลออกมาให้ดูง่าย เราจึงต้องเขียนลูปดังนี้</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">lda_model</span><span class="o">.</span><span class="n">num_topics</span><span class="p">):</span>
    <span class="n">keyword_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">lda_model</span><span class="o">.</span><span class="n">show_topic</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
    <span class="nb">print</span> <span class="p">(</span><span class="sa">f</span><span class="s1">&#39;หัวเรื่อง </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">: </span><span class="si">{</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">keyword_list</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>ผลลัพธ์ที่ได้จะมีลักษณะดังนี้</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">หัวเรื่อง</span> <span class="mi">0</span><span class="p">:</span> <span class="n">flight</span> <span class="n">good</span> <span class="n">food</span> <span class="n">crew</span> <span class="n">service</span> <span class="n">cabin</span> <span class="n">time</span> <span class="n">seats</span> <span class="n">friendly</span> <span class="n">staff</span>
<span class="n">หัวเรื่อง</span> <span class="mi">1</span><span class="p">:</span> <span class="n">luggage</span> <span class="n">bag</span> <span class="n">baggage</span> <span class="n">pay</span> <span class="n">kg</span> <span class="n">extra</span> <span class="n">carry</span> <span class="n">bags</span> <span class="n">checked</span> <span class="n">wow</span>
<span class="n">หัวเรื่อง</span> <span class="mi">2</span><span class="p">:</span> <span class="n">de</span> <span class="n">la</span> <span class="n">que</span> <span class="n">volotea</span> <span class="n">el</span> <span class="n">en</span> <span class="n">las</span> <span class="n">con</span> <span class="n">por</span> <span class="n">un</span>
<span class="n">หัวเรื่อง</span> <span class="mi">3</span><span class="p">:</span> <span class="n">airline</span> <span class="n">air</span> <span class="n">flights</span> <span class="n">airlines</span> <span class="n">service</span> <span class="n">fly</span> <span class="n">time</span> <span class="n">like</span> <span class="n">flying</span> <span class="n">low</span>
<span class="n">หัวเรื่อง</span> <span class="mi">4</span><span class="p">:</span> <span class="n">seat</span> <span class="n">seats</span> <span class="n">extra</span> <span class="n">flight</span> <span class="n">row</span> <span class="n">paid</span> <span class="n">get</span> <span class="n">front</span> <span class="n">plane</span> <span class="n">back</span>
<span class="n">หัวเรื่อง</span> <span class="mi">5</span><span class="p">:</span> <span class="n">luggage</span> <span class="n">baggage</span> <span class="n">lost</span> <span class="n">bag</span> <span class="n">bags</span> <span class="n">claim</span> <span class="n">days</span> <span class="n">manila</span> <span class="n">arrived</span> <span class="n">suitcase</span>
<span class="n">หัวเรื่อง</span> <span class="mi">6</span><span class="p">:</span> <span class="n">ticket</span> <span class="n">pay</span> <span class="n">check</span> <span class="n">service</span> <span class="n">online</span> <span class="n">customer</span> <span class="n">airline</span> <span class="n">website</span> <span class="n">said</span> <span class="n">told</span>
<span class="n">หัวเรื่อง</span> <span class="mi">7</span><span class="p">:</span> <span class="n">johannesburg</span> <span class="n">china</span> <span class="n">kuala</span> <span class="n">lumpur</span> <span class="n">test</span> <span class="n">town</span> <span class="n">cape</span> <span class="n">klm</span> <span class="n">chinese</span> <span class="n">shanghai</span>
<span class="n">หัวเรื่อง</span> <span class="mi">8</span><span class="p">:</span> <span class="n">flight</span> <span class="n">us</span> <span class="n">plane</span> <span class="n">airport</span> <span class="n">boarding</span> <span class="n">staff</span> <span class="n">time</span> <span class="n">gate</span> <span class="n">passengers</span> <span class="n">minutes</span>
<span class="n">หัวเรื่อง</span> <span class="mi">9</span><span class="p">:</span> <span class="n">flight</span> <span class="n">airline</span> <span class="n">hours</span> <span class="n">get</span> <span class="n">us</span> <span class="n">service</span> <span class="n">customer</span> <span class="n">day</span> <span class="n">time</span> <span class="n">would</span>
</pre></div>
</div>
<p>จากนั้นเราต้องนำหัวเรื่องแต่ละหัวเรื่องมาตีความต่อ</p>
<ul class="simple">
<li><p>หัวเรื่อง 0: บริการบนเครื่องบิน</p></li>
<li><p>หัวเรื่อง 1: การจ่ายค่าบริการเกี่ยวกับน้ำหนักกระเป๋าที่สามารถนำขึ้นเครื่องได้</p></li>
<li><p>หัวเรื่อง 2: เป็นคำศัพท์ภาษาสเปนที่ส่วนใหญ่เป็นคำหยุด ทำให้เห็นว่าข้อมูลเราอาจจะมีข้อมูลที่ไม่เป็นภาษาสเปนติดมาด้วย เราควรจะกลับไปกรองออกก่อนให้เรียบร้อย</p></li>
<li><p>หัวเรื่อง 3: บริการของสายการบิน</p></li>
<li><p>หัวเรื่อง 4: ที่นั่งบนเครื่องบิน</p></li>
<li><p>หัวเรื่อง 5: การสูญหายของกระเป๋า</p></li>
<li><p>หัวเรื่อง 6: การซื้อตั๋วและการบริการลูกค้าออนไลน์ ผ่านหน้าเว็บไซต์</p></li>
<li><p>หัวเรื่อง 7: สถานที่เป็นปลายทางการบิน</p></li>
<li><p>หัวเรื่อง 8: ประสบการณ์การเช็คอินและขึ้นเครื่อง</p></li>
<li><p>หัวเรื่อง 9: ระยะเวลาที่แผนกบริการลูกค้าใช้ในการตอบกลับลูกค้า</p></li>
</ul>
<p>ถ้าหากว่าผลลัพธ์ออกมาไม่ดีเท่าทีควร มีทางแก้อยู่สองทางด้วยกัน</p>
<ol class="arabic simple">
<li><p>ลองเปลี่ยนจำนวนหัวเรื่อง ถ้าจำนวนหัวเรื่องมากเกินไป เราจะพบเห็นหัวเรื่องที่ซ้ำ ๆ กัน ถ้าจำนวนหัวเรื่องน้อยเกินไป เราจะพบเห็นหัวที่มีคำที่ไม่เกี่ยวข้องกันอยู่ด้วย ดังนั้นเราควรจะลองเปลี่ยนจำนวนหัวเรื่องใหม่อีกครั้ง</p></li>
<li><p>ทำความสะอาดข้อมูลให้ดีขึ้น หากเจอคำที่เกิดขึ้นในหลาย ๆ หัวเรื่องที่ไม่ได้มีประโยชน์ในการตีความ ทำความเข้าใจหัวเรื่อง อาจจะสกัดเอาคำเหล่านั้นออกไป เช่น ในตัวอย่างข้างต้น เราอาจจะเอาคำว่า <em>flight</em> และ <em>flights</em> ออกไปเนื่องจาก เราทราบอยู่แล้วว่าข้อมูลเกี่ยวกับสายการบิน คำว่า <em>flight</em> ย่อมปรากฏอยู่ในทุกรีวิว และไม่มีประโยชน์ในการตีความหัวเรื่อง</p></li>
</ol>
</section>
<section id="id11">
<h2>สรุป<a class="headerlink" href="#id11" title="Permalink to this heading">#</a></h2>
<p>ในบทนี้เราเรียนรู้เทคนิควิธีการประมวลผลภาษาธรรมชาติที่ใช้บ่อย ๆ ได้แก่ การติดป้ายกำกับชนิดของคำ การรู้จำเอนทิตี การวิเคราะห์อารมณ์ความรู้สึก การวิเคราะห์หัวเรื่องที่ปรากฏในชุดเอกสาร ในปัจจุบันมีไลบรารีที่สามารถดึงโมเดลต่าง ๆ ลงมาใช้ในภาษาไพทอนได้สะดวก เนื่องจากมีซอฟต์แวร์ที่เป็นโอเพนซอร์สมากมายที่ได้รับการพัฒนาอย่างต่อเนื่อง ทำให้สามารถทำการประมวลผลภาษาธรรมชาติได้ง่ายขึ้น หรือสามารถเทรนโมเดลบนชุดข้อมูลของเราเองอย่างการทำโมเดลหัวเรื่องได้</p>
</section>
<section id="id12">
<h2>อ้างอิง<a class="headerlink" href="#id12" title="Permalink to this heading">#</a></h2>
<div class="docutils container" id="id13">
<dl class="citation">
<dt class="label" id="id33"><span class="brackets"><a class="fn-backref" href="#id10">1</a></span></dt>
<dd><p>David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. <em>Journal of machine Learning research</em>, 3(Jan):993–1022, 2003.</p>
</dd>
<dt class="label" id="id28"><span class="brackets"><a class="fn-backref" href="#id5">2</a></span></dt>
<dd><p>Matthew Honnibal and Ines Montani. spaCy 2: natural language understanding with Bloom embeddings, convolutional neural networks and incremental parsing. To appear, 2017.</p>
</dd>
<dt class="label" id="id32"><span class="brackets"><a class="fn-backref" href="#id8">3</a></span></dt>
<dd><p>Hao Lang, Yinhe Zheng, Yixuan Li, SUN Jian, Fei Huang, and Yongbin Li. A survey on out-of-distribution detection in nlp. <em>Transactions on Machine Learning Research</em>, 2023.</p>
</dd>
<dt class="label" id="id29"><span class="brackets"><a class="fn-backref" href="#id3">4</a></span></dt>
<dd><p>Slav Petrov, Dipanjan Das, and Ryan McDonald. A universal part-of-speech tagset. In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Mehmet Uğur Doğan, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, <em>Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC'12)</em>, 2089–2096. Istanbul, Turkey, May 2012. European Language Resources Association (ELRA). URL: <a class="reference external" href="http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf">http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf</a>.</p>
</dd>
<dt class="label" id="id31"><span class="brackets"><a class="fn-backref" href="#id7">5</a></span></dt>
<dd><p>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In <em>Proceedings of the 2013 conference on empirical methods in natural language processing</em>, 1631–1642. 2013.</p>
</dd>
<dt class="label" id="id30"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p>Jakapun Tachaiya, Joobin Gharibshah, Kevin E Esterling, and Michalis Faloutsos. Raffman: measuring and analyzing sentiment in online political forum discussions with an application to the trump impeachment. In <em>Proceedings of the International AAAI Conference on Web and Social Media</em>, volume 15, 703–713. 2021.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./book/module9"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../9-nlp-models.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">โมเดลการประมวลภาษาธรรมชาติ</p>
      </div>
    </a>
    <a class="right-next"
       href="4-workshop-word-cloud.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Workshop - Word cloud</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">การติดป้ายกำกับชนิดของคำ</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">การจำแนกชนิดของคำ</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">การรู้จำเอนทิตี</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#spacy">ไลบรารี spacy สำหรับการติดป้ายชนิดของคำ และการรู้จำเอนทิตี</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#sentiment-analysis">การวิเคราะห์อารมณ์ความรู้สึก (Sentiment Analysis)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#huggingface-transformers">แพลตฟอร์ม huggingface และไลบรารี transformers สำหรับการวิเคราะห์อารมณ์ความรู้สึก</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">โมเดลหัวเรื่อง</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gensim-lda">ไลบรารี gensim สำหรับการฝึกโมเดล LDA</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">สรุป</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">อ้างอิง</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Attapol Thamrongrattanarit
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>