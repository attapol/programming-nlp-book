{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# เฉลยโจทย์: การประมวลผลข้อมูลจากไฟล์\n",
    "## โจทย์การเขียนเรกเอกซ์\n",
    "\n",
    "### ข้อ 1: ทะเบียนรถ\n",
    "- **เรกเอกซ์**: `[A-Z]{2}\\d{3,4}`\n",
    "- **คำอธิบาย**:\n",
    "  - `^[A-Z]{2}`: ขึ้นต้นด้วยอักษรภาษาอังกฤษตัวพิมพ์ใหญ่ 2 ตัว\n",
    "  - `\\d{3,4}`: ตามด้วยตัวเลข 3 หรือ 4 ตัว\n",
    "\n",
    "### ข้อ 2: รหัสสีแบบ 6 หลักในระบบฐานสิบหก\n",
    "- **เรกเอกซ์**: `#[0-9a-fA-F]{6}`\n",
    "- **คำอธิบาย**:\n",
    "  - `[0-9a-fA-F]{6}`: ตามด้วยตัวเลข 0-9 หรือ a-f หรือ A-F จำนวน 6 ตัว\n",
    "\n",
    "### ข้อ 3: ชื่อคนไทยที่ประกอบด้วยตัวอักษรไทยเท่านั้น\n",
    "- **เรกเอกซ์**: `[ก-์]{2,}`\n",
    "- **คำอธิบาย**:\n",
    "  - `^[ก-์]{2,}`: ต้องมีตัวอักษรไทย 2 ตัวหรือมากกว่า\n",
    "\n",
    "### ข้อ 4 ชื่อผู้ใช้งาน\n",
    "- **เรกเอกซ์**: `[a-z][a-z0-9_.]*[a-z0-9]`\n",
    "- **คำอธิบาย**:\n",
    "  - `[a-z]`: ต้องขึ้นต้นด้วยอักษรภาษาอังกฤษตัวพิมพ์เล็ก\n",
    "  - `[a-z0-9_.]*`: ประกอบด้วยอักษรภาษาอังกฤษตัวพิมพ์เล็ก ตัวเลข และเครื่องหมาย _ หรือ . ได้หลายตัว\n",
    "  - `[a-z]`: ลงท้ายด้วยอักษรภาษาอังกฤษตัวพิมพ์เล็ก หรือตัวเลข\n",
    "\n",
    "### ข้อ 5 เบอร์โทรศัพท์ไทย\n",
    "- **เรกเอกซ์**: `0\\d{9}`\n",
    "- **คำอธิบาย**:\n",
    "  - `^0`: ขึ้นต้นด้วยเลข 0\n",
    "  - `\\d{9}`: ตามด้วยตัวเลข 9 ตัว\n",
    "\n",
    "### ข้อ 6 ที่อยู่\n",
    "- **เรกเอกซ์**: `[ก-ฮ0-9/ ]+`\n",
    "- **คำอธิบาย**:\n",
    "  - `^[ก-ฮ0-9/]+`: ต้องประกอบด้วยตัวอักษรไทย ตัวเลข และเครื่องหมาย / อย่างน้อยหนึ่งตัว\n",
    "\n",
    "### ข้อ 7 สกุลไฟล์\n",
    "- **เรกเอกซ์**: `[a-zA-Z].*\\.((txt)|(csv)|(json))$`\n",
    "- **คำอธิบาย**:\n",
    "  - `[a-zA-Z]`: ต้องขึ้นต้นด้วยตัวอักษรภาษาอังกฤษตัวเล็กหรือตัวใหญ่\n",
    "  - `.*`: แทนตัวอักษรใดก็ได้ 0 ตัวหรือมากกว่า\n",
    "  - `\\.((txt)|(csv)|(json))`: นามสกุลไฟล์ต้องเป็น .txt, .csv หรือ .json\n",
    "\n",
    "### ข้อ 8 อีเมลล์\n",
    "- **เรกเอกซ์**: `[a-zA-Z0-9]+@(gmail|yahoo)\\.com`\n",
    "- **คำอธิบาย**:\n",
    "  - `[a-zA-Z0-9]+`: ขึ้นต้นด้วยตัวอักษร ตัวเลข อย่างน้อย 1 ตัว\n",
    "  - `@(gmail|yahoo)\\.com`: ลงท้ายด้วย @gmail.com หรือ @yahoo.com\n",
    "\n",
    "### ข้อ 9 วันเดือน\n",
    "- **เรกเอกซ์**: `^(0[1-9]|[12][0-9]|3[01])/(0[1-9]|1[0-2])$`\n",
    "- **คำอธิบาย**:\n",
    "  - `^(0[1-9]|[12][0-9]|3[01])`: วันที่ต้องอยู่ระหว่าง 01-09 หรือ 10-29 หรือ 30-31\n",
    "  - `/(0[1-9]|1[0-2])`: เดือนต้องอยู่ระหว่าง 01-09 หรือ 10-12\n",
    "\n",
    "### ข้อ 10 ขึ้นต้นอะไรก็ได้แต่ต้องลงท้ายด้วยสระ า\n",
    "- **เรกเอกซ์**: `([ก-์]*[^เ ][ก-ฮ][่-๋]?า)|([ก-ฮ][่-๋]?า)`\n",
    "- **คำอธิบาย**: แบ่งเป็นสองส่วนหลัก โดยใช้ตัวแบ่งคือ `|`\n",
    "  - ส่วนแรก: `([ก-์]*[^เ ][ก-ฮ][่-๋]?า)` เพื่อจับคำที่มีหลายพยางค์\n",
    "    - `([ก-์]*)`: จับคู่ตัวอักษรไทยตั้งแต่ตัวใดตัวหนึ่งไปจนถึงตัว \"์\" (ไม้ไต่คู้) หรืออักษรใดๆ ในช่วงนี้ ได้ตั้งแต่ 0 ตัวขึ้นไป\n",
    "    - `[^เ ]`: ต้องไม่ใช่สระ \"เ\" หรือช่องว่าง ( ) ตัวนี้ใช้เพื่อป้องกันการจับคู่คำที่มี \"เ\" นำหน้า เช่น \"เกา\" ไม่ให้ถูกจับคู่\n",
    "    - `[ก-ฮ]`: จับคู่ตัวอักษรไทยในช่วงตั้งแต่ \"ก\" ถึง \"ฮ\" ที่ตามหลังตัวที่ไม่ใช่ \"เ\"\n",
    "    - `[่-๋]?`: จับคู่รูปวรรณยุกต์ไทย เช่น ไม้เอก ไม้โท เป็นต้น แต่มีหรือไม่มีก็ได้\n",
    "    - `า`: จับคู่สระ \"า\" ซึ่งเป็นตัวอักษรสุดท้ายของคำ\n",
    "  - ส่วนที่สอง: `([ก-ฮ][่-๋]?า)` เพื่อจับคำพยางค์เดียวที่ออกเสียงเป็น \"า\"\n",
    "    - `[ก-ฮ]`: จับคู่ตัวอักษรไทยตั้งแต่ \"ก\" ถึง \"ฮ\"\n",
    "    - `[่-๋]?`: จับคู่รูปวรรณยุกต์ไทย (ไม้เอก, ไม้โท, ฯลฯ) มีหรือไม่มีก็ได้\n",
    "    - `า`: จับคู่สระ \"า\" เป็นตัวสุดท้ายของคำ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFJNT7NgXQbR"
   },
   "source": [
    "## โจทย์ปัญหาการประมวลผลข้อมูลจากไฟล์\n",
    "###  ข้อ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# สร้าง Counter เพื่อเก็บค่า part-of-speech tags และคำ\n",
    "pos_counter = Counter()\n",
    "word_counter = Counter()\n",
    "\n",
    "# กำหนดรูปแบบ regex เพื่อค้นหาคำและ part-of-speech tags\n",
    "pattern = r'(\\S+?)_([A-Za-z$]+)'\n",
    "\n",
    "# เปิดไฟล์และอ่านไฟล์ทีละบรรทัด\n",
    "with open('obama.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # ค้นหาคำทั้งหมดที่ตรงกับ pattern ในบรรทัดปัจจุบัน\n",
    "        matches = re.findall(pattern, line)\n",
    "        \n",
    "        # อัพเดต Counter ด้วยค่าที่พบ\n",
    "        pos_counter.update(pos for word, pos in matches)\n",
    "        word_counter.update(word for word, pos in matches)\n",
    "\n",
    "# ดึงข้อมูล part-of-speech tags ที่มีความถี่สูงสุดและคำ 100 คำแรก\n",
    "pos_freq = pos_counter.most_common()\n",
    "top_100_word = word_counter.most_common(100)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"\\nความถี่ของ Part-of-Speech Tags:\")\n",
    "for pos, freq in pos_freq:\n",
    "    print(f\"{pos}: {freq}\")\n",
    "\n",
    "print(\"\\nคำ 100 คำแรกที่มีความถี่สูงสุด:\")\n",
    "for word, freq in top_100_word:\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqnLI4XMYvRp"
   },
   "source": [
    "###  ข้อ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อ 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMNwUfxqZPAC"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def is_name_like(word):\n",
    "    pattern = r'^[A-Z][a-z]*$'\n",
    "    # ใช้ re.match เพื่อตรวจสอบว่าคำตรงกับแพตเทิร์นหรือไม่ และแปลงผลลัพธ์เป็นบูลีน\n",
    "    return bool(re.match(pattern, word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อ 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eY02ZvLyZkGP"
   },
   "outputs": [],
   "source": [
    "def get_all_names(sentence):\n",
    "  pattern = r'\\b[A-Z][a-z]*\\b'\n",
    "  # ใช้ re.findall เพื่อค้นหาคำทั้งหมดที่ตรงกับ pattern ในประโยค\n",
    "  names = re.findall(pattern, sentence)\n",
    "  return names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ข้อ 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOIqB6gbeg9U"
   },
   "outputs": [],
   "source": [
    "def censor_names(sentence):\n",
    "  pattern = r'\\b[A-Z][a-z]*\\b'\n",
    "  # ใช้ re.sub เพื่อแทนที่คำที่ตรงกับ pattern ด้วย \"XXX\"\n",
    "  censored_sentence = re.sub(pattern, 'XXX', sentence)\n",
    "  return censored_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecCBUoyu0F3R"
   },
   "source": [
    "###  ข้อ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1o934pH0GA6"
   },
   "outputs": [],
   "source": [
    "def autoanswer(question):\n",
    "    # ตรวจสอบว่าประโยคขึ้นต้นด้วย \"Do\" หรือ \"Does\" หรือไม่\n",
    "    match = re.match(r'^(Do|Does) (.*)', question)\n",
    "    if match:\n",
    "        # ถ้าเป็นประโยคคำถามที่ขึ้นต้นด้วย \"Do\" หรือ \"Does\"\n",
    "        verb = match.group(1)\n",
    "        rest_of_sentence = match.group(2)\n",
    "        # แทนที่ \"Do\" หรือ \"Does\" ด้วย \"do\" หรือ \"does\" ตามลำดับ\n",
    "        response_verb = \"do\" if verb == \"Do\" else \"does\"\n",
    "        # สร้างคำตอบในรูปแบบ \"Yes, ... do/does ...\"\n",
    "        return f\"Yes, {rest_of_sentence.split()[0]} {response_verb} {rest_of_sentence[len(rest_of_sentence.split()[0])+1:]}.\"\n",
    "    else:\n",
    "        # ถ้าไม่ใช่ประโยคคำถามที่ขึ้นต้นด้วย \"Do\" หรือ \"Does\"\n",
    "        return f\"{question}?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xn_M7evLX18o"
   },
   "source": [
    "### ข้อ 4\n",
    "#### ข้อ 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_MsH1aFbfzQ"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# อ่านไฟล์ nyt_eng_200001\n",
    "with open('small_nyt_eng_200001', 'r') as file:\n",
    "    s = file.read()\n",
    "\n",
    "# หาคำที่ขึ้นต้นด้วยตัว k\n",
    "pattern_start_k = r'\\bk\\w*'\n",
    "start_k_words = re.findall(pattern_start_k, s)\n",
    "\n",
    "# หาคำที่ตัวที่สองเป็นตัว k\n",
    "pattern_second_k = r'\\b\\w*k\\w*'\n",
    "second_k_words = re.findall(pattern_second_k, s)\n",
    "\n",
    "# หาคำที่ลงท้ายด้วยตัว k\n",
    "pattern_end_k = r'\\b\\w*k\\b'\n",
    "end_k_words = re.findall(pattern_end_k, s)\n",
    "\n",
    "# นับจำนวนคำที่ตรงกับแต่ละ pattern\n",
    "total_words = len(start_k_words) + len(second_k_words) + len(end_k_words)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"จำนวนคำที่ขึ้นต้นด้วยตัว k:\", len(start_k_words))\n",
    "print(\"จำนวนคำที่ตัวที่สองเป็นตัว k:\", len(second_k_words))\n",
    "print(\"จำนวนคำที่ลงท้ายด้วยตัว k:\", len(end_k_words))\n",
    "print(\"จำนวนคำที่มีคุณสมบัติตรงตามที่กำหนดทั้งหมด:\", total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOKkzIQtdzVx"
   },
   "source": [
    "#### ข้อ 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkXNl9EwfQsV"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# อ่านไฟล์ nyt_eng_200001\n",
    "with open('small_nyt_eng_200001', 'r') as file:\n",
    "    s = file.read()\n",
    "\n",
    "# หาคำที่ขึ้นต้นด้วยตัว k\n",
    "pattern_start_k = r'\\bk\\w*'\n",
    "start_k_words = set(re.findall(pattern_start_k, s))\n",
    "\n",
    "# หาคำที่ตัวที่สองเป็นตัว k\n",
    "pattern_second_k = r'\\b\\w{k}\\w*'\n",
    "second_k_words = set(re.findall(pattern_second_k, s))\n",
    "\n",
    "# หาคำที่ลงท้ายด้วยตัว k\n",
    "pattern_end_k = r'\\b\\w*k\\b'\n",
    "end_k_words = set(re.findall(pattern_end_k, s))\n",
    "\n",
    "# รวมคำที่ไม่ซ้ำจากทั้งสามชุด\n",
    "all_k_words = start_k_words.union(second_k_words).union(end_k_words)\n",
    "\n",
    "# นับจำนวนคำที่ไม่ซ้ำกัน\n",
    "total_unique_words = len(all_k_words)\n",
    "\n",
    "# แสดงผลลัพธ์\n",
    "print(\"จำนวนคำที่ขึ้นต้นด้วยตัว k (ไม่ซ้ำ):\", len(start_k_words))\n",
    "print(\"จำนวนคำที่ตัวที่สองเป็นตัว k (ไม่ซ้ำ):\", len(second_k_words))\n",
    "print(\"จำนวนคำที่ลงท้ายด้วยตัว k (ไม่ซ้ำ):\", len(end_k_words))\n",
    "print(\"จำนวนคำที่มีคุณสมบัติตรงตามที่กำหนดทั้งหมด (ไม่ซ้ำ):\", total_unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ข้อ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def find_names(announcement_file):\n",
    "    # เปิดไฟล์ประกาศเพื่ออ่านข้อมูล\n",
    "    with open(announcement_file, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "      \n",
    "    # กำหนด pattern ของ regex เพื่อจับชื่อในวงเล็บที่มีคำนำหน้าว่า นาย นางสาว หรือ นาง\n",
    "    pattern = r'\\((นาย|นางสาว|นาง)(\\S+)'\n",
    "    \n",
    "    # ใช้ re.findall เพื่อหาข้อความทั้งหมดที่ตรงกับ pattern ใน text\n",
    "    # re.findall จะคืนค่าเป็นลิสต์ของ tuple ที่แต่ละ tuple มีสองส่วนคือคำนำหน้าและชื่อ\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    # สร้างลิสต์เปล่าเพื่อเก็บชื่อผู้ชายและผู้หญิง\n",
    "    male_names = []\n",
    "    female_names = []\n",
    "    \n",
    "    # ลูปผ่านผลลัพธ์ที่จับได้จาก regex\n",
    "    for title, name in matches:\n",
    "        # ถ้าคำนำหน้าเป็น \"นาย\" ให้เพิ่มชื่อไปยังลิสต์ male_names\n",
    "        if title == \"นาย\":\n",
    "            male_names.append(name)\n",
    "        # ถ้าคำนำหน้าเป็น \"นางสาว\" หรือ \"นาง\" ให้เพิ่มชื่อไปยังลิสต์ female_names\n",
    "        else:\n",
    "            female_names.append(name)\n",
    "    \n",
    "    # คืนค่าลิสต์ชื่อผู้ชายและผู้หญิง\n",
    "    return male_names, female_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ข้อ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import โมดูล regular expression เพื่อใช้ในการหาคำ\n",
    "import re \n",
    "\n",
    "def count_en_th_words(word_list):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "    >>> count_en_th_words(['รองเท้า', 'ไม่', 'match', 'กับ', 'coat', 'เลย'])\n",
    "    {'en': 2, 'th': 4}\n",
    "    \"\"\"\n",
    "    # สร้าง dict ที่มีค่าเริ่มต้นของจำนวนคำภาษาอังกฤษและภาษาไทยเป็น 0\n",
    "    result_dict = {'en': 0, 'th': 0}\n",
    "    # วนลูปผ่านคำในรายการคำ\n",
    "    for w in word_list:\n",
    "        # ตรวจสอบว่าคำเป็นภาษาอังกฤษหรือไม่\n",
    "        if re.search('[a-zA-Z]', w):\n",
    "            # ถ้าใช่ เพิ่มจำนวนคำภาษาอังกฤษขึ้น 1\n",
    "            result_dict['en'] += 1\n",
    "        else:\n",
    "            # ถ้าไม่ใช่ เพิ่มจำนวนคำภาษาไทยขึ้น 1\n",
    "            result_dict['th'] += 1\n",
    "\n",
    "    return result_dict"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PC7 Regular Expression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "34368ba4908ea1be08ba769dfb7764ab7f8ead2384ebb5604cb86637573696f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
